2024-04-19 17:40:22,076 - distributed.utils - INFO - Reload module MofkaSchedulerPlugin from .py file
2024-04-19 17:40:22,126 - distributed.preloading - INFO - Import preload module: MofkaSchedulerPlugin.py
2024-04-19 17:40:22,127 - distributed.scheduler - INFO - -----------------------------------------------
2024-04-19 17:40:22,131 - distributed.preloading - INFO - Creating preload: MofkaSchedulerPlugin.py
2024-04-19 17:40:22,131 - distributed.utils - INFO - Reload module MofkaSchedulerPlugin from .py file
2024-04-19 17:40:22,137 - distributed.preloading - INFO - Import preload module: MofkaSchedulerPlugin.py
2024-04-19 17:40:22,709 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-04-19 17:40:22,746 - distributed.scheduler - INFO - State start
2024-04-19 17:40:22,749 - distributed.scheduler - INFO - -----------------------------------------------
/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py:181: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to hostname: [Errno 101] Network is unreachable
  warnings.warn(
2024-04-19 17:40:22,753 - distributed.scheduler - INFO -   Scheduler at:   tcp://10.201.1.129:8786
2024-04-19 17:40:22,754 - distributed.scheduler - INFO -   dashboard at:  http://10.201.1.129:8787/status
2024-04-19 17:40:22,756 - distributed.preloading - INFO - Run preload setup: MofkaSchedulerPlugin.py
2024-04-19 17:40:23,579 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-04-19 17:40:26,178 - distributed.scheduler - INFO - Receive client connection: Client-e7f9a5ee-fe73-11ee-a853-6805cae1dd68
2024-04-19 17:40:26,711 - distributed.core - INFO - Starting established connection to tcp://10.201.1.128:46434
2024-04-19 17:40:31,226 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.175:43971', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,226 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.175:43971
2024-04-19 17:40:31,226 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:40816
2024-04-19 17:40:31,227 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.175:32939', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,227 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.175:32939
2024-04-19 17:40:31,227 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:40836
2024-04-19 17:40:31,228 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.175:35851', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,229 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.175:35851
2024-04-19 17:40:31,229 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:40804
2024-04-19 17:40:31,229 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.175:33535', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,230 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.175:33535
2024-04-19 17:40:31,230 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:40824
2024-04-19 17:40:31,289 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.112:37409', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,289 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.112:37409
2024-04-19 17:40:31,289 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:60416
2024-04-19 17:40:31,290 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.112:40795', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,290 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.112:40795
2024-04-19 17:40:31,290 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:60414
2024-04-19 17:40:31,291 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.112:42593', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,291 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.112:42593
2024-04-19 17:40:31,291 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:60398
2024-04-19 17:40:31,292 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://10.201.1.112:32865', status: init, memory: 0, processing: 0>
2024-04-19 17:40:31,292 - distributed.scheduler - INFO - Starting worker compute stream, tcp://10.201.1.112:32865
2024-04-19 17:40:31,292 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:60428
2024-04-19 17:51:24,296 - distributed.worker - INFO - Run out-of-band function '_start_tracker'
2024-04-19 17:51:26,008 - distributed.scheduler - INFO - Receive client connection: Client-worker-7126b4e0-fe75-11ee-a28a-6805cae1e1b6
2024-04-19 17:51:26,009 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:57940
2024-04-19 17:51:26,009 - distributed.scheduler - INFO - Receive client connection: Client-worker-7126a076-fe75-11ee-a28c-6805cae1e1b6
2024-04-19 17:51:26,010 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:57930
2024-04-19 17:51:26,010 - distributed.scheduler - INFO - Receive client connection: Client-worker-7126a9e4-fe75-11ee-a289-6805cae1e1b6
2024-04-19 17:51:26,011 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:57942
2024-04-19 17:51:26,015 - distributed.scheduler - INFO - Receive client connection: Client-worker-712616b9-fe75-11ee-a28b-6805cae1e1b6
2024-04-19 17:51:26,015 - distributed.core - INFO - Starting established connection to tcp://10.201.1.175:57950
2024-04-19 17:51:26,016 - distributed.scheduler - INFO - Receive client connection: Client-worker-71395400-fe75-11ee-9dd1-6805cae1de52
2024-04-19 17:51:26,017 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:56616
2024-04-19 17:51:26,018 - distributed.scheduler - INFO - Receive client connection: Client-worker-7139cbb8-fe75-11ee-9dd3-6805cae1de52
2024-04-19 17:51:26,018 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:56634
2024-04-19 17:51:26,018 - distributed.scheduler - INFO - Receive client connection: Client-worker-7139dae9-fe75-11ee-9dd2-6805cae1de52
2024-04-19 17:51:26,019 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:56624
2024-04-19 17:51:26,019 - distributed.scheduler - INFO - Receive client connection: Client-worker-7139c685-fe75-11ee-9dd8-6805cae1de52
2024-04-19 17:51:26,020 - distributed.core - INFO - Starting established connection to tcp://10.201.1.112:56650
2024-04-19 17:54:32,122 - distributed.worker - INFO - Run out-of-band function '_start_tracker'
2024-04-19 17:57:20,731 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-19 17:57:59,627 - distributed.worker - INFO - Run out-of-band function '_start_tracker'
2024-04-19 18:01:03,108 - distributed.worker - INFO - Run out-of-band function '_start_tracker'
2024-04-19 18:03:35,208 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-19 18:03:49,698 - distributed.core - INFO - Event loop was unresponsive in Scheduler for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-19 18:04:38,973 - distributed.worker - INFO - Run out-of-band function '_start_tracker'
2024-04-19 18:07:25,363 - distributed.scheduler - INFO - Retire worker addresses {'tcp://10.201.1.112:32865': {'type': 'Worker', 'id': 'tcp://10.201.1.112:32865', 'host': '10.201.1.112', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-a05jhdc6', 'name': 'tcp://10.201.1.112:32865', 'nthreads': 8, 'memory_limit': 540332142592, 'last_seen': 1713550044.2974293, 'services': {'dashboard': 39189}, 'metrics': {'task_counts': {'released': 404, 'memory': 78, 'executing': 1}, 'bandwidth': {'total': 280369502.1395757, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0014896392822265625, 'profile-duration': 0.005971431732177734, 'tick-duration': 0.4989151954650879, ('execute', 'pd_split', 'memory-read', 'count'): 2, ('execute', 'pd_split', 'memory-read', 'bytes'): 1955456068, ('execute', 'pd_split', 'thread-cpu', 'seconds'): 17.781081220999994, ('execute', 'pd_split', 'thread-noncpu', 'seconds'): 4.76010320435401, ('execute', 'pd_split', 'executor', 'seconds'): 0.002138066804036498, ('execute', 'pd_split', 'other', 'seconds'): 0.0011842239182442427, ('execute', 'mean_chunk', 'memory-read', 'count'): 1, ('execute', 'mean_chunk', 'memory-read', 'bytes'): 384, ('execute', 'mean_chunk', 'thread-cpu', 'seconds'): 8.817399998406472e-05, ('execute', 'mean_chunk', 'thread-noncpu', 'seconds'): 4.152570704718528e-05, ('execute', 'mean_chunk', 'executor', 'seconds'): 0.0007891980931162834, ('execute', 'mean_chunk', 'other', 'seconds'): 0.0005676671862602234}, 'managed_bytes': 40546485941, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 50, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 167}, 'event_loop_interval': 0.02040774968205666, 'cpu': 304.5, 'memory': 60914221056, 'time': 1713550043.7951465, 'host_net_io': {'read_bps': 2253.5072321547073, 'write_bps': 7089.032972973786}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.112:41295'}, 'tcp://10.201.1.112:37409': {'type': 'Worker', 'id': 'tcp://10.201.1.112:37409', 'host': '10.201.1.112', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-48c5w3u0', 'name': 'tcp://10.201.1.112:37409', 'nthreads': 8, 'memory_limit': 540332142592, 'last_seen': 1713550044.2968047, 'services': {'dashboard': 44483}, 'metrics': {'task_counts': {'released': 375, 'memory': 69}, 'bandwidth': {'total': 469899687.34498274, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0012857913970947266, 'tick-duration': 0.5012452602386475}, 'managed_bytes': 37744782039, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 108, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 107}, 'event_loop_interval': 0.02000373363494873, 'cpu': 99.9, 'memory': 53315821568, 'time': 1713550043.7918332, 'host_net_io': {'read_bps': 2509.9612986538664, 'write_bps': 13938.67839021554}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.112:45141'}, 'tcp://10.201.1.112:40795': {'type': 'Worker', 'id': 'tcp://10.201.1.112:40795', 'host': '10.201.1.112', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-mg6rsln1', 'name': 'tcp://10.201.1.112:40795', 'nthreads': 8, 'memory_limit': 540332142592, 'last_seen': 1713550044.297007, 'services': {'dashboard': 39279}, 'metrics': {'task_counts': {'released': 303, 'memory': 57}, 'bandwidth': {'total': 272417042.0912561, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0013017654418945312, 'tick-duration': 0.5004119873046875}, 'managed_bytes': 29551784474, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 84, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 98}, 'event_loop_interval': 0.019985179901123046, 'cpu': 104.0, 'memory': 40713064448, 'time': 1713550043.793177, 'host_net_io': {'read_bps': 2250.2065197114753, 'write_bps': 10434.957700742016}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.112:44601'}, 'tcp://10.201.1.112:42593': {'type': 'Worker', 'id': 'tcp://10.201.1.112:42593', 'host': '10.201.1.112', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-1tigyfoe', 'name': 'tcp://10.201.1.112:42593', 'nthreads': 8, 'memory_limit': 540332142592, 'last_seen': 1713550044.297213, 'services': {'dashboard': 36381}, 'metrics': {'task_counts': {'released': 466, 'memory': 94}, 'bandwidth': {'total': 760559767.430454, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0015041828155517578, 'tick-duration': 0.4984316825866699}, 'managed_bytes': 35650571543, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 150, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 84}, 'event_loop_interval': 0.02000486373901367, 'cpu': 103.9, 'memory': 48753975296, 'time': 1713550043.7945032, 'host_net_io': {'read_bps': 2508.3285091204357, 'write_bps': 10526.592015584249}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.112:38653'}, 'tcp://10.201.1.175:32939': {'type': 'Worker', 'id': 'tcp://10.201.1.175:32939', 'host': '10.201.1.175', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-tbs0tp6p', 'name': 'tcp://10.201.1.175:32939', 'nthreads': 8, 'memory_limit': 540332130304, 'last_seen': 1713550044.7421772, 'services': {'dashboard': 38035}, 'metrics': {'task_counts': {'released': 689, 'memory': 109, 'executing': 1}, 'bandwidth': {'total': 345858999.5543749, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0015659332275390625, 'tick-duration': 0.5121891498565674, 'transfer-bandwidth': 692565.9215473279, 'transfer-duration': 0.020483016967773438, ('gather-dep', 'decompress', 'seconds'): 2.290797419846058e-05, ('gather-dep', 'deserialize', 'seconds'): 0.00015951716341078281, ('gather-dep', 'network', 'seconds'): 0.020300591830164194, ('gather-dep', 'other', 'seconds'): 0.02957785874605179, ('execute', 'mean_combine-partial', 'memory-read', 'count'): 8, ('execute', 'mean_combine-partial', 'memory-read', 'bytes'): 3072, ('execute', 'mean_combine-partial', 'thread-cpu', 'seconds'): 0.00025504899997486064, ('execute', 'mean_combine-partial', 'thread-noncpu', 'seconds'): 5.537199001537374e-05, ('execute', 'mean_combine-partial', 'executor', 'seconds'): 0.0011730720289051533, ('execute', 'mean_combine-partial', 'other', 'seconds'): 0.0013620408717542887, ('execute', 'mean_agg-aggregate', 'memory-read', 'count'): 2, ('execute', 'mean_agg-aggregate', 'memory-read', 'bytes'): 768, ('execute', 'mean_agg-aggregate', 'thread-cpu', 'seconds'): 0.00039112600000024145, ('execute', 'mean_agg-aggregate', 'thread-noncpu', 'seconds'): 2.8013862060305428e-05, ('execute', 'mean_agg-aggregate', 'executor', 'seconds'): 0.0007074661552906036, ('execute', 'mean_agg-aggregate', 'other', 'seconds'): 0.002994086127728224, ('execute', 'reshape', 'memory-read', 'count'): 1, ('execute', 'reshape', 'memory-read', 'bytes'): 8, ('execute', 'reshape', 'thread-cpu', 'seconds'): 1.3735999999653359e-05, ('execute', 'reshape', 'thread-noncpu', 'seconds'): 2.2980461181987266e-05, ('execute', 'reshape', 'executor', 'seconds'): 0.0007132363971322775, ('execute', 'reshape', 'other', 'seconds'): 0.0019301972351968288}, 'managed_bytes': 26214314894, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 156, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 120}, 'event_loop_interval': 0.02036683900015695, 'cpu': 102.0, 'memory': 35250610176, 'time': 1713550044.2295983, 'host_net_io': {'read_bps': 31369.00980663259, 'write_bps': 9861.802420086176}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 67}, 'status': 'running', 'nanny': 'tcp://10.201.1.175:42227'}, 'tcp://10.201.1.175:33535': {'type': 'Worker', 'id': 'tcp://10.201.1.175:33535', 'host': '10.201.1.175', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-pqadjlnv', 'name': 'tcp://10.201.1.175:33535', 'nthreads': 8, 'memory_limit': 540332130304, 'last_seen': 1713550044.732863, 'services': {'dashboard': 42339}, 'metrics': {'task_counts': {'released': 463, 'memory': 83}, 'bandwidth': {'total': 266348950.61423388, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0018329620361328125, 'tick-duration': 0.4992334842681885}, 'managed_bytes': 42121314100, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 85, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 167}, 'event_loop_interval': 0.020417481052632233, 'cpu': 101.9, 'memory': 56135561216, 'time': 1713550044.2326057, 'host_net_io': {'read_bps': 32094.019211079798, 'write_bps': 7662.274715441805}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.175:42835'}, 'tcp://10.201.1.175:35851': {'type': 'Worker', 'id': 'tcp://10.201.1.175:35851', 'host': '10.201.1.175', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-cbzmmy3q', 'name': 'tcp://10.201.1.175:35851', 'nthreads': 8, 'memory_limit': 540332130304, 'last_seen': 1713550044.2313476, 'services': {'dashboard': 34761}, 'metrics': {'task_counts': {'released': 466, 'memory': 83}, 'bandwidth': {'total': 362292273.44555146, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.0016493797302246094, 'tick-duration': 0.499814510345459}, 'managed_bytes': 35298032589, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 124, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 91}, 'event_loop_interval': 0.02002688407897949, 'cpu': 104.1, 'memory': 49134845952, 'time': 1713550043.73151, 'host_net_io': {'read_bps': 16705.295143589556, 'write_bps': 19229.30391139047}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 67}, 'status': 'running', 'nanny': 'tcp://10.201.1.175:43437'}, 'tcp://10.201.1.175:43971': {'type': 'Worker', 'id': 'tcp://10.201.1.175:43971', 'host': '10.201.1.175', 'resources': {}, 'local_directory': '/tmp/dask-scratch-space/worker-2uir_1wn', 'name': 'tcp://10.201.1.175:43971', 'nthreads': 8, 'memory_limit': 540332130304, 'last_seen': 1713550044.7299368, 'services': {'dashboard': 46813}, 'metrics': {'task_counts': {'released': 495, 'memory': 92}, 'bandwidth': {'total': 414847549.75923544, 'workers': {}, 'types': {}}, 'digests_total_since_heartbeat': {'latency': 0.001340627670288086, 'tick-duration': 0.5001966953277588, ('get-data', 'memory-read', 'count'): 2, ('get-data', 'memory-read', 'bytes'): 768, ('get-data', 'serialize', 'seconds'): 0.0001909458078444004, ('get-data', 'compress', 'seconds'): 1.4804769307374954e-05, ('get-data', 'network', 'seconds'): 0.006013636477291584}, 'managed_bytes': 32891851917, 'spilled_bytes': {'memory': 0, 'disk': 0}, 'transfer': {'incoming_bytes': 0, 'incoming_count': 0, 'incoming_count_total': 82, 'outgoing_bytes': 0, 'outgoing_count': 0, 'outgoing_count_total': 84}, 'event_loop_interval': 0.020006351470947266, 'cpu': 101.9, 'memory': 44053970944, 'time': 1713550044.2292135, 'host_net_io': {'read_bps': 31334.851197821605, 'write_bps': 10186.622967165362}, 'host_disk_io': {'read_bps': 0.0, 'write_bps': 0.0}, 'num_fds': 66}, 'status': 'running', 'nanny': 'tcp://10.201.1.175:45513'}}
2024-04-19 18:07:25,363 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.175:33535' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,366 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.175:32939' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,369 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.112:32865' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,371 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.175:43971' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,375 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.112:42593' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,376 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.112:37409' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,378 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.112:40795' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,379 - distributed.scheduler - INFO - Retiring worker 'tcp://10.201.1.175:35851' (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,381 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.175:33535, but 81 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,382 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.112:37409, but 69 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,382 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.112:42593, but 93 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,382 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.112:32865, but 74 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,383 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.175:32939, but 102 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,383 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.175:35851, but 82 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,383 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.112:40795, but 56 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,384 - distributed.active_memory_manager - WARNING - Tried retiring worker tcp://10.201.1.175:43971, but 92 tasks could not be moved as there are no suitable workers to receive them. The worker will not be retired.
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.175:33535': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.175:32939': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.112:32865': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.175:43971': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.112:42593': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.112:37409': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.112:40795': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:25,385 - distributed.scheduler - WARNING - Could not retire worker 'tcp://10.201.1.175:35851': unique data could not be moved to any other worker (stimulus_id='retire-workers-1713550045.3634827')
2024-04-19 18:07:28,493 - distributed.scheduler - INFO - Scheduler closing due to unknown reason...
2024-04-19 18:07:28,494 - distributed.scheduler - INFO - Scheduler closing all comms
2024-04-19 18:07:28,495 - distributed.core - INFO - Connection to tcp://10.201.1.175:40816 has been closed.
2024-04-19 18:07:28,495 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.175:43971', status: running, memory: 92, processing: 0> (stimulus_id='handle-worker-cleanup-1713550048.4956462')
2024-04-19 18:07:28,496 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.175:43971' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-47b5bc14-e224-4025-8ec2-7f2168830c3c', 'dict-3ec829fb-f6e0-4639-907a-ecb9b1039723', 'dict-852ff0bc-66d1-4095-955f-c3cf5d9c3a94', 'dict-d6a8a1da-a77b-422b-bf85-5fa5be61f2cd', 'dict-cc094bf5-d5c5-4443-8206-28086a6a8aff', 'dict-689d94ac-1794-4e51-8f02-c9bc8cf8b488', 'dict-827e9d9b-302e-442d-adf5-4cc3767a6b1d', 'dict-9d666047-6ff7-4383-90f7-e2e16b865558', 'dict-84c69419-e94b-490d-b188-ef8c2a558a72', 'dict-0b1ee914-12a2-40b2-bc8c-0b5fe412d25f', 'dict-4eca6174-a356-4ef4-a2fb-e574912e22bd', 'dict-d3a2c5a3-d858-4fbc-adc7-ad124053482a', 'dict-da71e77b-2ef1-4678-b8d7-ea99be375395', 'dict-b046b99a-f9ea-4af4-8d46-7d9062c51111', 'dict-59ee5b85-f3c4-4663-8344-c956ef5e3cee', 'dict-51513c06-d9bf-4ab2-b16e-dce887f9a857', 'dict-792ebfc5-dd20-4fd4-87ac-d78366256c9a', 'dict-d4209b7a-5db4-416e-9014-4371150caaf3', 'dict-7726ef3c-40b0-4924-bbb4-560fca8a9af6', 'dict-d997636c-eb0a-4637-8d12-af6c20dd523e', 'dict-d051aa0f-3953-4b22-849e-5f6aa6b27610', 'dict-3322c645-b389-4b66-a80e-ee6119f3c69a', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 9), 'dict-714bd168-4a4c-45ed-8073-76895462fe1f', 'dict-067b3bd0-d99b-4023-a469-1af0b52c1b12', 'dict-1ef64e7d-badd-4424-95c6-485c723f1f1c', 'dict-6948df78-33af-4ee1-aa5d-1ae94f055e53', 'dict-67104785-8705-49e4-9065-6d0ba63913f2', 'dict-f775e76d-158f-4889-86db-c27d3ae7552a', 'dict-712349f5-dae5-4c48-9513-b5d631c07faa', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 66), 'dict-90bcb18e-23bc-42bf-8420-d4df2c50eb55', 'dict-3673ac46-89c8-4943-b345-05d379bbb269', 'dict-41830286-1034-43cb-885a-81fa5f848bc1', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 68), 'dict-aa72c204-f2e5-4a1a-97b0-d32ac2b05199', 'dict-d7b80e52-0c56-483e-8daa-286b7e00ddc2', 'dict-17c22ec9-6c11-4c5f-88b6-c2366d95373b', 'dict-a985e310-eb56-4acf-a387-7caf8e4a40c9', 'dict-769a20f1-39ba-4fc0-a1a7-69233793a754', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 70), 'dict-fc376a5f-294e-4f73-8fb2-cae16c1613c7', 'dict-89d9ed96-980c-41e0-85d0-2ca75c5cc0a1', 'dict-43db189c-fe4a-4b1c-b7eb-fee488453656', 'dict-38f298fd-48b8-4b77-8ba0-4202299c95ce', 'dict-afafb458-c0c0-4635-ba18-e0f29d577454', 'dict-b36f2239-914a-4e0f-9bdf-3882842f7834', 'dict-3a72a5f4-55c7-4758-b92d-e2982238f74d', 'dict-e5c9524e-5665-45a8-bbc9-d328bc8939f5', 'dict-14b413c0-2430-4ed8-8807-2584e3451914', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 8), 'dict-80234dcc-9d82-47d1-ace6-884e8cca9e3f', 'dict-8d15e46e-bd2b-49f9-857b-39e8eb0c86c1', 'dict-dc1b4fa5-e6cd-4f61-8d2b-b288c656841b', 'dict-9b4d7ffe-ea98-4f40-9e48-028785787b97', 'dict-d00616ea-2de2-4365-9d0f-2ed94fa64a0d', 'dict-656ee90f-c2df-442c-959d-16cff8314148', 'dict-d3191895-66cf-44e0-8695-734d33148e80', 'dict-4227da56-ccb2-4376-9374-ce087acc531f', 'dict-cf23a048-eff8-484e-91ef-0656f46f78a4', 'dict-637233d5-5892-40bf-a22b-0371c18d7363', 'dict-bc025561-bc17-424f-b07f-b2ba0a4d5167', 'dict-4a3e75ab-911e-4958-8fd9-a96a36204033', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 67), 'dict-ebc017d6-4eba-4893-aa22-5aebc92e86c5', 'dict-1553aae2-3f12-4f24-a510-e17cb9d25513', 'dict-dd70932e-299e-4ad2-8a0e-de31af82f0e2', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 33), 'dict-0bad41ce-9a3b-4f34-8ff4-e23d7928d1ed', 'dict-077731f8-cfb3-464b-9c35-313a76e0022b', 'dict-e72181d9-63d8-453b-b11f-c492f1ce0390', 'dict-96de2bf5-a09e-4e1d-8012-c02467c9c1e3', 'dict-da72543e-1974-4095-b159-181b4660bf27', 'dict-3bf81445-5aa7-4f46-b777-71cd8fb4820a', 'dict-30cac282-e4a8-42cf-b614-dc377b36f2f1', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 69), 'dict-cd871661-f6a2-469b-85c0-f2bea78c14d0', 'dict-f9197e7a-7321-47c1-8551-69011a1628be', 'dict-0150d6d6-e9ae-4a38-88d4-fdb84a378897', 'dict-b78410fe-c0e1-45eb-91af-9ca891d8d1a7', 'dict-869d9ccf-fcbe-42cd-9f7d-b6c3392039d7', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 7), 'dict-dfa0cb9b-63c1-4992-b2d4-9697aa836d5a', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 71), 'dict-4709b752-c143-4192-ab75-333da90040c4', 'dict-341540e0-29f0-4fb0-9448-259f59388f0c', 'dict-3d6a5fa3-8553-4a6c-a968-aa9629563e4e', 'dict-68165be2-21d3-4233-9fa2-54cd0c56b1fc', 'dict-3f4ce512-b2b3-4e15-ad18-b8c639adaa27', 'dict-de0b6517-d8bd-4426-b346-cda857e5439d', 'dict-867733bc-6d3c-4e45-8c44-ed7bafb1dc2e', 'dict-8b81d287-2ad4-4576-add4-4332c38c96c2'} (stimulus_id='handle-worker-cleanup-1713550048.4956462')
2024-04-19 18:07:29,127 - distributed.core - INFO - Connection to tcp://10.201.1.175:40836 has been closed.
2024-04-19 18:07:29,127 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.175:32939', status: running, memory: 102, processing: 2> (stimulus_id='handle-worker-cleanup-1713550049.1278474')
2024-04-19 18:07:29,128 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.175:32939' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-5a4068c8-b3d1-49d2-b50a-2f1cef591b27', 'dict-7e1e7071-efff-43a4-b446-1584b5918578', 'dict-7bbf0e0c-21e9-48e7-8b6e-a78e012b5e3b', 'dict-2b79f1bf-3dd7-4e22-b73b-2bd1907c5c8e', 'dict-ba79845b-c83b-4fa2-8aa6-b080d842e891', 'dict-632439fa-8578-4c47-af52-57cde2af8d3b', 'dict-7225ab99-e6bb-464e-bd82-0839a8985b1a', 'dict-11d3d37e-9bbd-465a-88a7-ef07dceb4099', 'dict-eb768cdc-c7be-4950-a9a4-9ca3442405bc', 'dict-06911ad0-b76d-4e23-8194-3b13591a9142', 'dict-916b6747-dddc-4b35-bcfe-4432126392aa', 'dict-eca34b94-3559-4950-8cf9-d841d654e9c5', 'dict-3c36d9ff-8ee9-428c-ae74-7dca9b46125d', 'dict-6f3e57d1-4a1f-40cf-8835-6102382d5166', 'dict-9c19d068-91aa-487b-b684-7eb00c221ebb', 'dict-61f48d5f-9e68-4edb-a924-6ab62f87edcf', 'dict-12bb0043-cde5-464f-a12a-14ad3705a4e0', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 25), 'dict-1417004c-53dd-4940-80c9-212aa0b6522c', 'dict-58da014d-f024-4259-99bc-7af80ea6f602', 'dict-69cab3a5-0325-452d-a4e8-c385a8ff3c85', 'dict-33ca090f-a8fc-4c71-bb4a-4859bee18736', 'dict-7e61b034-d1dd-4428-882f-5ca580a6e2fc', 'dict-138ffe1d-7b8c-4816-b1d5-8e8dfb65bc24', 'dict-a5f4aedb-89f1-4bfa-8c8a-a8f8c75daac6', 'dict-5898d5d8-a226-4d70-a4f7-7c04590f460a', 'dict-2a743075-2c70-45da-ac75-b2c5a80863a6', 'dict-58c2729b-7197-4e4f-b134-32c205e28f2b', 'dict-951e5c1f-7362-44ea-a88b-693e6dbec35b', 'dict-f54ef1a6-119d-4ae9-832b-b72b04250e59', 'dict-be473e00-d8ec-4d3a-9270-86d63fdb141a', 'dict-105d4359-031e-4c18-a32f-0a43879fbfb7', 'dict-40e3b238-b876-4b0c-97ab-921210fb9454', 'dict-c28e9fb3-73c3-40e6-b9d2-31e836d21c6d', 'dict-8a5c96cc-61ad-422b-a1d1-9a8aaaaf40c5', 'dict-671796a0-0890-4443-bc20-78e1751941cd', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 59), 'dict-31c49a82-2264-4633-a58f-d354ca43c7d8', 'dict-e9e847bb-d620-41ef-8ef3-9a8341c35ad0', 'dict-f2b6ccb4-80a5-47f3-995b-fe454ae4ecae', 'dict-6292e81b-ca8d-4360-980e-acc791c80a0b', 'dict-bdede034-34db-4685-8251-b1d2db2f5ef8', 'dict-9096ce6d-da54-409a-91a4-68a3b0814aa7', 'dict-30bd67ca-5186-4a49-81b6-bf287f2b19f2', 'dict-983e0198-f89b-407a-8665-bd712d9c3899', 'dict-c2d4f67c-b9ae-4bb1-a303-0f79a2a4b070', 'dict-587374b0-ecab-47d8-9c88-3395a826bab3', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 61), ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 6), 'dict-f86769e9-71f5-4662-8dd4-3bb172b13c25', 'dict-b7e415f2-b072-4cfb-ba39-80f3945e8758', 'dict-8cc435c3-b9d8-46af-a0d0-eb812cb734e1', 'dict-25b8385e-7368-42d2-beb1-a13fe125a98b', 'dict-777a63b4-b4e0-4075-b1ab-d345d06bba1b', 'dict-0cb68d34-7cae-4bd9-b45b-f2ac5b697ec3', 'dict-fe06d430-059f-4adb-85fb-5625244c0758', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 63), ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 17), 'dict-6325a28e-520d-42d7-b75e-92f1cc23c666', 'dict-1231b0f6-594d-47fb-be14-7627dc82bafb', 'dict-0e69f7c8-1f0a-418f-8bff-b1b37dc87e2a', 'dict-1c90c685-47ec-4810-8ff3-29fbe39e2fe3', 'dict-94ba64b6-56db-4cb8-9d4b-933b66e0f538', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 56), 'dict-74be175a-48d4-464a-9e1e-f15c1594c82c', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 65), 'dict-879c9442-5f40-4daa-be0f-4a8a7fe94d9c', 'dict-6e8c7c20-7553-48c9-875f-9c17b21f4c6b', 'dict-b9fdccc7-2c42-4153-8e0f-54fab09c5bcb', 'dict-c01dd621-e4bb-4e11-883a-283e0d4eb41c', 'dict-fbd3a321-2d11-43b0-a072-ab4a80967909', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 58), 'dict-6bb0e18d-2458-40f2-b358-38ae328c9593', 'dict-36af13f4-60f9-466e-bbca-7fca190a2dee', 'dict-ac56b7f8-1f39-4946-8d04-e4616379b95b', 'dict-488964a8-d7e6-40f3-99f7-4c0c4e31fb37', 'dict-1d2b5754-3d37-44ea-a642-5a1a737bd827', 'dict-eb1ec9bc-da1b-40a6-b8a4-f75cf87307e3', 'dict-e3909997-37cd-4192-b4fc-80249bbcd9cf', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 60), 'dict-79693788-bb55-4b99-b0d0-e7674f5e1a3d', 'dict-e5936ee7-e143-4fbf-a947-841750eb4441', 'dict-7850f1dc-6633-47cb-a3f3-8ac71ba3c6a1', 'dict-cf5e681d-adc4-4621-9bdd-192c3620789b', 'dict-080cf213-8d87-40c2-b136-05562821bdbb', 'dict-57be88ae-edc7-4f20-9723-e9e4eb1f5a53', 'dict-0857cb3e-7f3f-478a-9731-a898c0a8c276', 'dict-9881ac5d-8edd-4ab9-8b5a-78e7d3781cc9', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 62), 'dict-716c4a73-9e7a-4023-8213-f378e4dd6503', 'dict-683809a6-3a31-406e-9846-ef3381df175e', 'dict-7967b093-2a2d-4bf3-aeb2-0bd479d82f54', 'dict-62496c65-6d42-4a89-84cd-d30072a101d3', 'dict-d02b5774-6118-48cc-a0c9-25207dce3729', 'dict-2b93f0e6-ca17-4f10-b3cf-56b82cda657d', 'dict-3f1dfb14-8e65-47db-a2c6-ca94ab4a17a3', 'dict-645eb0a1-dddb-4838-bf67-abe32e78a8b5', 'dict-76814801-7f09-41ad-9a3c-e840e836b89b', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 64), 'dict-57d74236-e92d-4d2b-82c9-abc01f1e5855', 'dict-d3543d72-2216-4c0b-be39-a9d5cff17742', 'dict-f1946926-8428-41b0-a262-bf79e8315401'} (stimulus_id='handle-worker-cleanup-1713550049.1278474')
2024-04-19 18:07:29,185 - distributed.core - INFO - Connection to tcp://10.201.1.175:40804 has been closed.
2024-04-19 18:07:29,185 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.175:35851', status: running, memory: 82, processing: 5> (stimulus_id='handle-worker-cleanup-1713550049.185382')
2024-04-19 18:07:29,185 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.175:35851' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-dfa9309c-3a0e-46b8-a593-bdbc795880e2', 'dict-be85a6cc-d319-4081-9ff4-7c897d204de3', 'dict-51c01e1f-d5ac-4b56-a7e8-467f5aa0bde0', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 57), 'dict-554592ce-62fb-482f-bfc8-aad502ffe70f', 'dict-6c85020b-c52b-4e46-9eda-c61887a7fdce', 'dict-2c88cfcf-6214-40cf-af96-a8b8ce1cecb7', 'dict-f0efc12f-d96e-4874-a453-1c366ac0043a', 'dict-8c575c76-b892-422f-aaa4-cfb22da74c13', 'dict-a1a2403f-6d48-4e91-93fc-6275067f93dd', 'dict-e8c5f631-1475-4924-94a3-4d434ff2186c', 'dict-8507a52f-aff2-4f78-82a7-145b6a8fba3b', 'dict-c4439d63-88ba-471e-84a4-063a8ce8846f', 'dict-7385ada3-f5ec-44f5-bd90-0457c9957950', 'dict-d520b9a8-ce9e-47ec-9072-53b85f92e384', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 50), 'dict-38f8a275-4d24-42da-9019-bdfb5ba63313', 'dict-48b20c88-46f0-45c8-a219-493340469cbb', 'dict-d6a9a9db-0bdb-4e9b-8053-9c0ff13039c2', 'dict-3ef8efae-749f-42ad-9a04-23ac52d37ee4', 'dict-562d4b87-a998-4da1-9ff3-00ad84378562', 'dict-bf308acb-2986-45c2-99fc-7eefc04138d7', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 52), 'dict-6c3dea07-b291-4ce1-a23c-97d4f7ae459f', 'dict-4a3cf6cb-c81b-4967-a758-f32a21671af7', 'dict-68bdf4d0-88c4-4c2b-b325-abdad49b36a5', 'dict-e4ed1db9-71a3-4330-927e-097415d8538b', 'dict-97474910-a613-4df1-ab7e-f65cbc0aaa36', 'dict-e476cc24-002d-4727-b2e8-b2f2790bb6d5', 'dict-07c693ff-8c2e-4a2c-af98-1286a324b6b7', 'dict-6b649799-e233-4518-b329-6dd1dc4e9f5c', 'dict-18ef638c-a45b-4cf3-823b-151bcff3ce1f', 'dict-0734a0ab-975b-4265-8123-be47586c7dcc', 'dict-855d6d73-394e-4a81-a438-eb70f589513e', 'dict-58fc9472-a3c4-4d47-9cc5-5c2e9497af2c', 'dict-cbe44e35-58dc-4839-be7c-6475295ee72b', 'dict-d4712746-5419-4332-aee7-4675c377409b', 'dict-c3e0c8e4-cd90-4ad3-80df-8b5395ad91be', 'dict-004f0fac-b23d-4198-9170-aabcff31a07c', 'dict-10b48c88-bcef-4d25-9165-60fedf916a81', 'dict-c99b5cd6-fd57-457b-8ddc-bd46ab362d0a', 'dict-761b70af-1c89-4037-8aba-7a75590ecea3', 'dict-9d03f402-f399-4b01-b1b1-36f45ab6d64b', 'dict-7a04e2a8-903e-4586-9c6d-9da382974521', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 54), 'dict-86e82e77-a930-4acc-baa4-1e9b533b8c2e', 'dict-627419a8-0e1c-4cad-9a08-3d9971678454', 'dict-559b3e6b-d9e7-447a-b181-f750fe81ffe2', 'dict-0d2dae2a-3f25-43bd-85f1-3dd9568c9442', 'dict-f1b139b9-3972-43a2-86b6-3a560a185776', 'dict-d1dc8764-52c6-4acc-ba8d-14cdd76e9416', 'dict-31baa0be-edb6-46b6-a25b-833e536f0d55', 'dict-2b8c16aa-dc5d-44b1-a770-00e9ae15a9d9', 'dict-72bed1d5-e7ea-435c-a731-33e56d4fa5f8', 'dict-b30ce64c-b240-4e61-84f6-b443e9f3ab78', 'dict-b682499c-dad8-4a1c-b9ad-7f71158498a8', 'dict-32816654-43a9-490e-b99d-a8ea4dc99c58', 'dict-0d938ecc-5e7c-4e35-a179-c22e31e8400d', 'dict-d6436cab-0b04-42c3-a0e6-e1d79410af00', 'dict-95db8f28-8e47-49a0-82da-1e09d47ed15a', 'dict-9cb9eb05-9b16-4a30-8f92-373c5d34ebd8', 'dict-283e980f-3165-4fa9-a2cd-4714f53ccf17', 'dict-5456eedd-72e1-47b9-ae7a-196aaf96a1f5', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 51), 'dict-c001bcd5-5b11-4274-b17a-5ee3d2acd6cc', 'dict-66b1fd3a-f6f8-40cb-82b7-029ee16d3360', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 5), 'dict-7036a466-6d13-42d8-9f42-2f6e0b343dc2', 'dict-31addc87-4533-4638-8754-881ee0f7ec53', 'dict-0fc989ef-8f95-49f2-80a2-b62ff17af5ad', 'dict-72d8e7b3-11db-491d-a579-3978357f95ed', 'dict-149a0a5a-441a-445a-8be8-5f05e1372f87', 'dict-1f11d238-5b8a-4b4f-86bb-57d1888e004c', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 53), 'dict-a88f5484-7beb-43a7-8521-189674139f85', 'dict-9893fb63-b216-4ccf-9a92-622c40fbf5b7', 'dict-456e914c-7c84-43a8-a85a-d45a23608b9c', 'dict-49dfbd2c-5419-460b-86a1-256239a7e5b3', 'dict-e98096ee-faa8-4eb5-acf0-62f9df62bdcb', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 55), 'dict-4ca693f6-6a87-4ed1-83c0-45d7bbdec544', 'dict-5e4d562e-1fbb-47fa-ab2f-0ace3a0edb0b'} (stimulus_id='handle-worker-cleanup-1713550049.185382')
2024-04-19 18:07:29,233 - distributed.core - INFO - Connection to tcp://10.201.1.175:40824 has been closed.
2024-04-19 18:07:29,233 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.175:33535', status: running, memory: 81, processing: 8> (stimulus_id='handle-worker-cleanup-1713550049.233369')
2024-04-19 18:07:29,233 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.175:33535' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-d42851d4-69ca-45b6-8f2e-e629e0c40cf8', 'dict-aadfe920-c206-42cc-bd6d-09c3b939d434', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 48), 'dict-50ed500c-42ad-42fd-be9b-f29633bd9d32', 'dict-c4daccac-9272-4e7f-bef9-f6de5c72cb39', 'dict-3bd039be-48a1-4c6a-8395-c99430c12bbe', 'dict-d28d4358-0b49-4008-98bf-16de060ad799', 'dict-49b37c4a-a31e-4a3d-9aee-ab72049c8b1f', 'dict-b8ede18a-3eb7-464e-be29-88d7dbade1a0', 'dict-71864c43-d9a8-4e91-8040-64dffe114770', 'dict-7647848c-630a-4138-b307-54751f568042', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 43), 'dict-1de37743-1e71-4000-ba6f-8a0244b21cd6', 'dict-6fe4aead-eb3b-44ef-83a3-f142dcfcb718', 'dict-ea3f0c13-13b0-4b66-886d-33ea442c9522', 'dict-fb36b975-4893-4287-893c-337eb1f909c2', 'dict-4dddad51-abc4-47a5-a42a-398d514447e0', 'dict-501df9cc-5a99-4619-a649-febd44cfd651', 'dict-9ee04179-2c98-4222-bfda-19cff98b92da', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 45), 'dict-97251059-de9c-4450-8599-7f1d0525d792', 'dict-83ffa48b-b2c5-4cbc-ab11-bc7e363bcb14', 'dict-70ab599a-160b-48f2-af29-90338ee49e49', 'dict-b71b4ad3-2aee-4b90-a8d0-8464ab875af4', 'dict-2ea9176c-076c-4315-9c0a-fac1e0fdcdff', 'dict-31164dfa-89a3-488a-94e3-5c1132d9522f', 'dict-bf2e53bc-7474-4ca3-9147-66ec017dcb3d', 'dict-4b0bf17c-707b-4ecf-90aa-e477f818648f', 'dict-ef8c05c8-28f9-4349-8e86-2a991331342c', 'dict-5c62996d-22a9-4c59-833d-be1c2d60aa2f', 'dict-e2b265d5-bfaa-4292-9963-fc42284b2460', 'dict-57726a2f-382c-4020-ae8a-5a1742b2bd03', 'dict-31aeab5d-6d7d-461f-83b9-f6420e32bc2f', 'dict-da6d7cce-94a9-4d70-a61c-599772fedc0b', 'dict-9d44797e-3a5d-46f9-a7d5-6ec10c702a80', 'dict-2abbf43c-e817-4583-a862-9e62b5fcdf23', 'dict-4adc63c3-6678-487f-bc54-e4483f8822be', 'dict-9949091b-f5cd-4844-8212-70bc67604714', 'dict-1e9471bc-d5fe-4797-9d6e-4de4352e1b27', 'dict-0334f374-870f-49bb-bab5-8ace372f060f', 'dict-b8307b65-d376-4c7a-81de-719b6d3489bc', 'dict-85fbbfe3-71af-4ad6-9ba8-3273a2ed24de', 'dict-fcd106b2-7188-46e4-accf-eb402fb18646', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 47), 'dict-8a6dba32-ea7d-4c33-a426-33f8c2eb43f4', 'dict-218a0f11-9a53-43ac-864a-d262e9fb7b9b', 'dict-59b130bf-af56-4774-98d6-686ea5bfc7c1', 'dict-80d5bbaa-e5e5-4d94-884b-f3d2877dc1a0', 'dict-78b0bfe7-d3aa-4674-ac64-0801853b8296', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 49), 'dict-ea41dbf3-862b-403f-9367-852711067263', 'dict-15ce5125-4fdd-4d26-a900-0be5fefc5cff', 'dict-cb24de6c-7245-473a-8b57-5fa7986b55c6', 'dict-8080d819-2d71-4f9d-bf5d-922918bddc8b', 'dict-a280c173-f374-4533-823b-adced7ca6f1d', 'dict-e88de90b-c1fd-489d-ad0a-c091fa3d284d', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 42), 'dict-14f5e82a-3b5c-495f-b78d-fe78c13eb442', 'dict-85dafff0-d71d-4861-9320-430e1c7e312d', 'dict-dd01db4d-c767-4183-9250-5e5dfe12da50', 'dict-8ab6e32c-9a77-4a83-b964-ec5c1c171848', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 44), 'dict-569e6c09-7b07-4342-9539-6e9e15b55dba', 'dict-262117cf-b489-4094-890c-0bb2bf7bf2d9', 'dict-4d8a00f9-b00c-43d8-8f83-a3ff50ee9306', 'dict-730fa261-e2cd-4ed6-8e04-99698ca4c821', 'dict-fe4a2b1e-b1d6-4ed8-bb49-5dd8b7b4ea39', 'dict-447e9d30-c4f4-4b8b-829d-3fe61caeca78', 'dict-727357fd-328b-44e5-a2c8-c2b119c280e4', 'dict-8ade198f-afa6-4472-875a-63090990eb12', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 46), 'dict-63ef13d6-1c7a-462f-bf0c-f26948185aef', 'dict-a345737d-4d5a-46dd-aed8-f4f956decd74', 'dict-5bfde428-2d6f-471c-ab52-0d48d95a6d3f', 'dict-70c4bc85-9513-4cae-8c3b-5c3f6753721f', 'dict-1dee0e76-0b31-4f84-a4f5-0918475bb47d', 'dict-acf5b977-96c0-47d3-ba5a-85ae640142b9', 'dict-6654b04f-512c-4092-8c07-77053d39d13c', 'dict-6912c000-f665-4382-b2e0-e229a8a5e849', 'dict-d64c3cbd-ffeb-4f70-9eb5-3cf0ff3b253a', 'dict-03d2c490-d224-4a23-a58e-8f2438497387'} (stimulus_id='handle-worker-cleanup-1713550049.233369')
2024-04-19 18:07:29,280 - distributed.core - INFO - Connection to tcp://10.201.1.112:60416 has been closed.
2024-04-19 18:07:29,280 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.112:37409', status: running, memory: 69, processing: 9> (stimulus_id='handle-worker-cleanup-1713550049.2802398')
2024-04-19 18:07:29,280 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.112:37409' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-1774790b-6e00-4b33-92eb-928376b2ad47', 'dict-9707f1d0-dd56-483b-a778-209e9ff3fa4e', 'dict-0cd728c1-a938-4e4e-9bcd-e30a64a4f319', 'dict-5ebc6f2e-e973-4da7-9d94-a48e0318176c', 'dict-3c51fb92-3a72-492d-b7b4-5aff9bacfbca', 'dict-ec1044bc-7f5e-46e3-a37f-ca18d9532432', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 36), 'dict-a8d01b11-2021-462f-81b9-56426d219ad0', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 39), 'dict-86519931-9c4e-44db-a27b-cb12213fbbe6', 'dict-3dcb42a6-3d60-453e-aa2b-ea6e54c62b07', 'dict-134c434f-19cf-40b0-b39f-0740f1ee76f1', 'dict-3eeb4997-3bff-4437-a147-02cfdff5acc0', 'dict-fda1790c-91c2-441e-87a4-630af1fc8ad2', 'dict-d04fce2b-1542-4ebf-8339-877fd0625ec6', 'dict-2c919c19-5cba-4b70-8353-cdbfc32fc660', 'dict-9d77fc13-833f-4883-9fef-7aa96e5a0fb5', 'dict-22000d1e-9214-4914-b566-d8fe911b83ad', 'dict-6b44eb48-2531-41d2-92e8-971cff8973a5', 'dict-3f13d00b-f62f-49fe-a672-407d8ebc80ed', 'dict-85ffb77d-5c35-4c38-a3b6-0cd519574f61', 'dict-fbbcc0ee-51fb-49de-ac50-92fe34e56aeb', 'dict-830e0d14-949f-47ae-861f-513bd108f38e', 'dict-55552aa4-3551-47df-a070-36ec9880969f', 'dict-abf216eb-5563-4bd5-a04d-806f44a5fbd6', 'dict-cab5ea8d-e8a7-407d-bb21-0725b672f339', 'dict-8e835f8b-b93b-49e8-a2d3-15387c9a04bc', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 38), 'dict-5c4454b3-6fff-4e0f-af1b-7064fe44b3a4', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 35), 'dict-2c33a054-8842-4145-955b-4ed09f161e8c', 'dict-d58cdd66-ebee-4a6b-bf01-01aa1fe2b898', 'dict-740af890-043d-44b4-8146-dfde12afa9e5', 'dict-91307871-6272-43db-9062-b333ecfe546e', 'dict-6f399af3-735f-4228-8891-5d1faf97aa1e', 'dict-4421249d-3993-48f3-acef-576be6b24153', 'dict-b38a6af8-7b75-4a41-919a-546b63ef85b9', 'dict-4ae8cded-dabd-45aa-8497-1074b80ab19e', 'dict-259b489b-c427-4f35-b726-1560cdeaa9e5', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 4), 'dict-162689f2-bf42-48ac-a815-f9181dbaa220', 'dict-b29d90d3-95ac-4758-8072-b15d041b5d30', 'dict-8f89d7d4-ec73-4599-b747-686a194d786d', 'dict-6474e29d-03d2-4740-ab7e-d7be5517ac93', 'dict-424f0add-9265-450a-b5ac-fc881720530f', 'dict-d1384acd-6446-4375-a5d3-a95882e8dfa1', 'dict-bb164a9d-24d8-4326-a970-64b79e6b0fcc', 'dict-cb5d633a-e222-433b-a1e7-a9375ba70645', 'dict-6dc329be-54a9-4443-841d-db085a0fed52', 'dict-b06877a2-386e-48f8-a89f-f1496491cb5b', 'dict-1c3da3f3-51c0-41b3-871d-749fca78de78', 'dict-9403ed94-a1de-40d7-b330-684a7dbc2904', 'dict-487c0a3d-9a9a-4bba-a8ee-aeda2cfa6edb', 'dict-9a827f12-3f6c-45d6-a14e-8c9313ecfb5b', 'dict-8de96056-a9dc-4114-8a12-34c503c9bcb0', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 34), 'dict-6696c28d-4fe6-43e9-823d-f7882486014f', 'dict-0692d8bf-ba2e-40dc-b31f-ea57672f2dea', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 37), 'dict-51adf3c3-0a1d-4cf3-b087-db17c3b1f142', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 40), 'dict-ae27d45a-c78f-4ccc-b5d3-2d1980b97f33', 'dict-7548ab58-ebd2-4410-99f3-04a0ffd7cdee', 'dict-0251abf4-16ef-4bc7-9edd-f123de906ea0', 'dict-060595ef-0449-4b53-84c3-05574d1924a5', 'dict-e82d5df5-e1fb-49c9-b62c-f6917cbe1f52', 'dict-342b8bcb-7a1e-4813-9d41-d03ec962b81d', 'dict-aee79e1a-7dcd-4fef-8290-08af615dbafe', 'dict-479c84e8-d59b-4c3e-bc7e-b607fe7b835f'} (stimulus_id='handle-worker-cleanup-1713550049.2802398')
2024-04-19 18:07:29,320 - distributed.core - INFO - Connection to tcp://10.201.1.112:60414 has been closed.
2024-04-19 18:07:29,320 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.112:40795', status: running, memory: 56, processing: 9> (stimulus_id='handle-worker-cleanup-1713550049.3202894')
2024-04-19 18:07:29,320 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.112:40795' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-bed9913b-67d1-441d-8b41-26d6b59e1438', 'dict-3e3caa2d-bc63-4607-9a1e-9c0abdd9aa46', 'dict-bcecc091-2b82-414c-b558-1e075a8a681f', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 27), ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 30), 'dict-d85e7ca3-7784-4a5c-af2b-9ff8c7a4f69e', 'dict-ff914f64-32f4-4630-9675-c19fc0f08e48', 'dict-7069b58a-2dcc-459b-9cb6-82cb9e279f3c', 'dict-6a444ed5-e17a-477d-890f-a45295508676', 'dict-21692ba4-c15e-46c8-9b5e-39b76e175512', 'dict-9ffedbf3-e788-41a7-a0a7-d49abfa7599d', 'dict-1efb8512-570c-455e-99a7-9fce624344f1', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 26), 'dict-f3035a33-6fc5-4df6-be0a-9ed4eef64b29', 'dict-42cedbaf-34ec-4ac3-af0e-8772dc8f42da', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 29), 'dict-4d974759-0d04-41f0-a931-6f746099eb8a', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 32), 'dict-d8d2f119-33e6-4a66-a543-df9372f4cdc1', 'dict-de740fe1-6d86-42df-8306-f6635646fb74', 'dict-b3e38498-7e41-4600-ac19-cd865e1da081', 'dict-0063d0c8-c034-4d3a-9f24-234947520597', 'dict-d2f23f83-e085-4a95-bedf-94e0bf675d7c', 'dict-f5bf616e-ecc4-4068-b14a-59098a63288d', 'dict-9af3328b-f727-4ad3-bc31-5596efb55f4c', 'dict-a9a5c663-63c5-4fa7-97a5-da00fb62a1ab', 'dict-c1a715fe-6dce-4e9b-aa7e-fc4455dc896b', 'dict-71abf707-4e72-4a83-a8be-ed3687fd667f', 'dict-6897ff76-6bba-4346-8c9a-23705cb2d5da', 'dict-707960c6-79ef-4f83-8224-ac5405054496', 'dict-0c9ff170-d674-459d-a65a-f415ebdd806f', 'dict-2ead1da1-0706-47a1-b297-51e9109f53d5', 'dict-4f572c75-0995-4734-8dd5-14bb41fc177e', 'dict-abe1bf7d-21a8-4280-912b-34033b61d706', 'dict-91318e63-dcf4-4e52-aae6-a7ed59ad3be1', 'dict-e2dfde20-ba18-4d92-9dc9-dce7f3107ddd', 'dict-d5bb14f4-c03c-4505-a92c-b1436d229b73', 'dict-7951a7ea-dc9c-460d-b484-799e02114ab3', 'dict-2d55dbb7-7f86-4b4d-bbfb-8e9cee968cd7', 'dict-0880f650-e0b5-45f1-af57-5e9c70ca33a7', 'dict-1e7b5687-2482-4c5f-b262-d33a0a3b6fe5', 'dict-2bc8e656-31db-40a5-97a2-30ec1f4873bb', 'dict-7bfb8947-8bee-4340-a01d-3f4b7eebea58', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 31), 'dict-d56ba824-d933-4590-95eb-f580ba0831c1', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 28), 'dict-4d09714c-64aa-4a37-8967-c347f0171945', 'dict-b1575b2e-c8c1-4b20-9ad7-41c511b3b535', 'dict-1619d604-da74-4b05-8949-de30a6726eea', 'dict-73ddf4f1-0f42-4696-a951-9016756957fd', 'dict-6fb5a1bb-dc75-49a0-91b4-0f1489a40f83', 'dict-ee1df6fe-d524-4c3e-a33c-c7393cb87e35', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 3), 'dict-67c2f7ba-965a-4242-b10a-c7b59f1fb9c3', 'dict-1c6a7b94-113b-4d81-84f0-76575f5cb9d7'} (stimulus_id='handle-worker-cleanup-1713550049.3202894')
2024-04-19 18:07:29,320 - distributed.scheduler - ERROR - Removing worker 'tcp://10.201.1.112:40795' caused the cluster to lose scattered data, which can't be recovered: {'Booster-0c08dbd63d8ff7effd23e083030a6b65'} (stimulus_id='handle-worker-cleanup-1713550049.3202894')
2024-04-19 18:07:29,351 - distributed.core - INFO - Connection to tcp://10.201.1.112:60398 has been closed.
2024-04-19 18:07:29,352 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.112:42593', status: running, memory: 93, processing: 9> (stimulus_id='handle-worker-cleanup-1713550049.3520317')
2024-04-19 18:07:29,352 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.112:42593' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 21), 'dict-09abf77a-4ddc-4b6b-accf-225f69701032', 'dict-550757d6-0431-421c-b83c-a65a193113df', 'dict-727f08aa-84c3-4f9d-ab35-c9226ad9f84f', 'dict-f58bb154-fe94-49a1-884e-5c1b67404688', 'dict-a8f96945-5e9e-488a-9327-4af1feeee8bd', 'dict-c5132ceb-b682-4757-a83c-b621f4325511', 'dict-c5ea2454-0655-4562-b2ab-69c88d83a460', 'dict-c23fa035-af15-4189-94a9-f0d649f838d1', 'dict-b9125a24-89f2-419e-b295-f73d25b7cb91', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 23), 'dict-0193f203-dc60-43d9-836b-d26d6cee3749', 'dict-8fe2eb92-d066-4f3d-aa0a-2158e4b2be81', 'dict-c6469b6e-06a2-4609-af46-fb38bd968038', 'dict-7ba861dc-3ae6-4814-8004-fd09094302be', 'dict-db6ba93a-f8f5-45b0-8737-1bf2fa9cbf4c', 'dict-d0edec68-f5f1-4a78-b231-293e69a5ba84', 'dict-0637294b-99db-4f42-a71b-e00de62dddd7', 'dict-c2dee1d5-40e2-48ba-ad3f-a5f7c5475bd4', 'dict-f86a9717-4074-4ac8-ae68-1f65e0079c06', 'dict-d8ce1995-4f2d-49a1-8e6b-66df8d9bbf49', 'dict-ca16b08d-81df-452b-88e6-b80a656181e7', 'dict-65b1afff-7ced-4bfb-a3c0-34137fa87b84', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 18), 'dict-30c545f0-aac2-4be6-9551-812af166a876', 'dict-532325df-a621-4961-81b3-2153d4f05a9c', 'dict-baa96d47-610e-41fb-be8a-05765c9947b0', 'dict-300ed7e8-eae0-47df-99d3-04d24d9e7676', 'dict-7a56a760-d6ea-4ef0-8d0f-8e34bd9e496b', 'dict-23ad5b89-a8e2-44c0-ac3a-644d9e51e32a', 'dict-906346ce-3144-47b0-aea3-bb746a6f734c', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 2), 'dict-a1001993-d7b5-480a-9bd5-42e89b7b4201', 'dict-6348b78e-6cf1-472e-a05d-6d1b6fe2954e', 'dict-06a6d2f5-216e-4759-84f2-fe6865f842f6', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 20), 'dict-810560a7-3f20-48f7-9417-5e3f8e0376a7', 'dict-a0db0e3a-65a1-4b14-87cd-3e73eccc88db', 'dict-94668f3e-5912-444c-9b99-d550c0620d6e', 'dict-14dd3966-553d-4f8c-8826-492b885fae02', 'dict-29a1e8ba-dedc-4f5a-a18b-59665e2b6d91', 'dict-c6821e37-1f1f-4ea6-8424-54cf0ea288e9', 'dict-b0f50025-85ae-421f-9211-95ce903fa5ef', 'dict-2728d6b9-bd43-4b81-9bc6-7745629156e4', 'dict-ed35138e-84bd-4bef-b6b0-d5d4f1e72e6f', 'dict-749a2696-7fbb-441d-86b2-57b85b23ba15', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 22), 'dict-da551e72-51ea-45c0-9f9d-c58bb942a220', 'dict-950ed830-74eb-4173-ab08-09a4c6c16bff', 'dict-c331f59b-9266-47b6-b9dc-e6c5e57d3f95', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 24), 'dict-d722640f-9841-4488-9e23-9c01d37805fc', 'dict-4a510a1f-c11e-435b-a445-d6c9bcd35e08', 'dict-921da3b7-ed6b-4c04-bf4c-047debcf7247', 'dict-ccb54c90-4654-40c2-a84b-c92e82abc9fc', 'dict-dde85aee-209e-4385-93d8-6a1ca37aacb1', 'dict-5222264c-d4a5-4ffb-adf1-ef614cdde542', 'dict-2d7478f2-0df8-4a20-a006-1be0f9f5134a', 'dict-bd7aa0c7-645b-4d16-a9b1-5e0df22fc3dc', 'dict-f28579ba-72b6-4c9b-841c-3836a53b87bc', 'dict-3105591a-ae8a-4f03-8cbc-099effec0768', 'dict-fbc3e273-1ef9-4fb2-a939-9f7953a56454', 'dict-7f6f6e7a-a6cb-41fd-a8f5-abfa923b72bd', 'dict-f2a440e5-7520-40ea-9076-984a69a2d45f', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 19), 'dict-ce72dfb5-9f18-45a2-8c1c-b4cfd429569b', 'dict-d68562e2-003d-466d-81fd-189ba7dce068', 'dict-9131e817-8051-48f0-9eb7-c9fd1d4c36ce', 'dict-4461116c-3cce-49e5-b435-556cbb0b5dc9', 'dict-21de0f46-9e03-40e6-8b63-5f2bc0e97bfa', 'dict-7e8edfde-512c-4648-b45f-5cd91edc51cc', 'dict-664a6dc1-52fa-4bb3-9627-0f99aa69e5d0', 'dict-91b5ecf4-9562-4a4f-af8f-9d9565bf0833', 'dict-e35581da-35d3-41d5-b0b6-3bb8a83f1f72', 'dict-c7ce8e22-bce2-46dc-a46a-2da5bb37b1d1', 'dict-751e1fa9-38ec-4618-9a13-f85008897cb7', 'dict-2d2820ad-f344-4dfd-8745-4b57da6276e3', 'dict-6f80466b-e382-4eb4-b7cb-28d81097b75c', 'dict-066043dc-342d-49f0-abe1-3b03e6225baa', 'dict-11f5fc58-c91f-4604-9d04-3cbeac51573b', 'dict-d82b606f-b5eb-4781-94cf-1d664c70a334', 'dict-23fc7862-725a-4245-b08a-a922f6f956f5', 'dict-7ae99bbe-2ce4-499c-a2de-1025553527ee', 'dict-35097cc6-b579-41a3-86f3-036831396c1b', 'dict-d6a6aa6b-0188-4f03-b101-ac6fdc4dfb9f', 'dict-d1c2bbdb-d480-40c2-affc-b5f71684c5a6', 'dict-40117c33-4a83-4b33-a061-d265a8907632', 'dict-bd7ce7e0-9a16-418d-a914-91c925727b76', 'dict-343b8cdd-5908-4928-9665-77b77f968a0c', 'dict-a3a65a3a-2ead-4d0f-b0ed-e8152a126664', 'dict-f01d8b77-49de-43bc-a135-0fba9acad273', 'dict-e4a0f284-efb9-463f-ae10-5f06185c584f', 'dict-0845133d-a58b-4153-bcb6-c68acb9deaf4'} (stimulus_id='handle-worker-cleanup-1713550049.3520317')
2024-04-19 18:07:29,406 - distributed.core - INFO - Connection to tcp://10.201.1.112:60428 has been closed.
2024-04-19 18:07:29,406 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://10.201.1.112:32865', status: running, memory: 74, processing: 12> (stimulus_id='handle-worker-cleanup-1713550049.406302')
2024-04-19 18:07:29,406 - distributed.scheduler - WARNING - Removing worker 'tcp://10.201.1.112:32865' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'dict-0e245f5b-188c-43eb-b620-452fab6fec0a', 'dict-a64e1f6f-62e5-450a-bf9d-967df58ae912', 'dict-8b81c470-40af-4092-87d4-dde33f3b923a', 'dict-78976519-f1cb-4617-9b17-3d94ef637830', 'dict-65178336-a5c1-4a77-99cd-a5d26f8de6e3', 'dict-3da78f77-725d-4493-ae82-81d0dcab4798', 'dict-cf41b1da-2a88-48df-91b4-0fe6fa285b63', 'dict-e5161095-8be8-4f0a-a605-a3cbf860c67f', 'dict-737ce6e3-35be-4810-9c58-16bd90ae228a', 'dict-293dd0f7-e743-40f0-a3d1-0e1bf77f0995', 'dict-7f029d25-45f8-4e56-804c-d819524d3e1d', 'dict-dc49a804-c65b-4361-b74d-510544d80c24', 'dict-f7ac2425-62c7-4082-b384-de5d99f2c294', 'dict-bd77920c-6719-4be0-8550-ec33915f298f', 'dict-327de961-d7c3-4c3b-830e-8e80583913e6', 'dict-28618dd5-b69d-4a4d-b348-b939f45a1b41', 'dict-c4f6f260-2bdc-4af4-aa04-07b0a31cdd99', 'dict-b2d2b8b5-2c3c-4526-ae27-401bac1520f4', 'dict-b5514d6f-993d-4ad3-a54c-d922149176be', 'dict-f9a13343-c406-499c-92f1-620ebfebc398', 'dict-5db1e4e9-8479-4f57-ac77-116a8b88ab03', 'dict-9d72cbf8-e66e-4342-a49c-ccf830d40053', 'dict-026a6280-03a4-4a42-b657-49ca79aac67d', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 11), ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 14), 'dict-149829e1-ac2e-42f3-989e-b1d5e327ce34', 'dict-3ab6fab5-91e6-4bb5-b8e2-877e3b89f1df', 'dict-9ba503e7-8bb9-403c-b144-2ee5b13e4cd4', 'dict-38f0cc67-6d88-41fd-9793-139edb611158', 'dict-a7105453-7da1-4395-960d-e478f0a6cccc', 'dict-3e7c58c8-cd56-4b96-93b8-735678aab669', 'dict-f2a1f9f9-7a32-416b-a78f-033656932595', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 41), 'dict-6219c3b0-8176-46f3-93b9-fe1ac350f7e1', 'dict-aec4c095-1583-47d8-8551-64da6e11c5d4', 'dict-db762be0-05c7-48a2-8027-d29a9c5ad2a6', 'dict-8f0ca5ea-73c4-4856-91a1-a6c79e28288f', 'dict-2f728145-e5a5-4413-9e82-ed5cdf0e7501', 'dict-ae02f6a9-fe68-41da-aacb-86836a65c1fe', 'dict-c427a32b-3d6a-4456-9543-2fca17ea7fea', 'dict-0cc53ba7-b0f6-4258-8818-3c27d767d57b', 'dict-5e230d58-38a8-48fb-bb0b-cd47b1ab809f', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 1), 'dict-e72aa9d5-3ad2-4cca-9221-8a57889d0ac2', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 10), 'dict-89f9ddbd-d6da-4586-9fb3-e96b11aeeec3', 'dict-db987eee-22da-418b-93c9-713f58f1095c', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 13), 'dict-a53c9ed1-5fe7-4b8d-9c04-3f1a022a9236', 'dict-9c847dff-31bb-4eed-93db-06ab362af57b', 'dict-ff1054f5-9fdb-4d06-8243-7a56df7a2d13', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 16), 'dict-394854d3-6a17-46b6-987b-9e6b9f249b4c', 'dict-fc1bdbd8-f64a-49ae-97e2-9a708e3f3f39', 'dict-fc292c6b-1026-4008-8bd7-db0766871f1b', 'dict-9e967ca7-1772-4b3e-aa1f-9785fa8984f5', 'dict-bcf2db72-01bb-4f50-8f39-dd6945b50f44', 'dict-4e0a65d8-d620-48d2-b895-0858d70f6faa', 'dict-145ff20d-b8f0-4c84-9e74-8341892f4de6', 'dict-697dba61-2808-4e45-a6ea-dd38bd702b19', 'dict-e9a7fdd0-1064-41ea-9ca0-05789806ab54', 'dict-95d1d7f4-2758-45d7-9822-d6388e469176', 'dict-74d430c7-d0d8-44f9-b9c6-56e6e3102b5a', 'dict-3092f365-8f2c-4088-9b60-7b9d8a723b3a', 'dict-03190923-a273-4094-b171-5e6cde7bd8b0', 'dict-e4948ff7-dd66-47d4-b6f4-30a547cb4d84', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 0), 'dict-1c749cf0-e11e-4179-91b3-de812ce71282', 'dict-880af1cc-7e9d-49be-9100-28d4042e3d1a', 'dict-640ae4b8-8c9f-42d3-b1ec-aeb2d862e264', 'dict-0a30375d-85a6-452a-b67f-bcd6265df8a2', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 12), 'dict-c8e90480-f340-41a4-a014-485013060d85', ('_categorize_block-b1c5d712038b82b9c12e85feee39d745', 15)} (stimulus_id='handle-worker-cleanup-1713550049.406302')
2024-04-19 18:07:29,448 - distributed.scheduler - INFO - Lost all workers
Function returned HG_PERMISSION
--- Logging error ---
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5713, in add_client
    await self.handle_stream(comm=comm, extra={"client": client})
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/lus/eagle/projects/radix-io/agueroudji/XGBoost/D2024-04-19_17:15:01_R48_W8/MofkaSchedulerPlugin.py", line 229, in transition
    f.wait()
pymofka_client.Exception: Unexpected error when sending batch: [/home/agueroudji/spack/opt/spack/linux-sles15-zen3/gcc-11.2.0/mochi-thallium-0.12.0-ow3bjypntyfbafke33olmxpdg46qgnpp/include/thallium/callable_remote_procedure.hpp:117][margo_provider_forward] Function returned HG_PERMISSION

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/dask/cli.py", line 209, in run_cli
    cli()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 636, in run_until_complete
    self.run_forever()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 603, in run_forever
    self._run_once()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 1909, in _run_once
    handle._run()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 970, in _handle_comm
    result = await result
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5715, in add_client
    self.remove_client(client=client, stimulus_id=f"remove-client-{time()}")
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5741, in remove_client
    self.client_releases_keys(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5430, in client_releases_keys
    self.transitions(recommendations, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 7984, in transitions
    self._transitions(recommendations, client_msgs, worker_msgs, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 2065, in _transitions
    new_recs, new_cmsgs, new_wmsgs = self._transition(key, finish, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 1964, in _transition
    a_recs, a_cmsgs, a_wmsgs = self._transition(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 2022, in _transition
    plugin.transition(
  File "/lus/eagle/projects/radix-io/agueroudji/XGBoost/D2024-04-19_17:15:01_R48_W8/MofkaSchedulerPlugin.py", line 231, in transition
    logging.exception("Exception while calling transition method when sending", str(transition_data))
Message: 'Exception while calling transition method when sending'
Arguments: ('{\'key\': "(\'getitem-57342c589e8a55cd05e8e60bd966f68a\', 121)", \'thread\': None, \'worker\': None, \'prefix\': \'getitem\', \'group\': \'getitem-57342c589e8a55cd05e8e60bd966f68a\', \'start\': \'waiting\', \'finish\': \'released\', \'stimulus_id\': \'remove-client-1713550049.4507859\', \'called_from\': \'tcp://10.201.1.129:8786\', \'begins\': None, \'ends\': None, \'duration\': None, \'size\': None, \'time\': 1713550050.0076675}',)
Function returned HG_PERMISSION
--- Logging error ---
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5713, in add_client
    await self.handle_stream(comm=comm, extra={"client": client})
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1025, in handle_stream
    msgs = await comm.read()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/lus/eagle/projects/radix-io/agueroudji/XGBoost/D2024-04-19_17:15:01_R48_W8/MofkaSchedulerPlugin.py", line 229, in transition
    f.wait()
pymofka_client.Exception: Unexpected error when sending batch: [/home/agueroudji/spack/opt/spack/linux-sles15-zen3/gcc-11.2.0/mochi-thallium-0.12.0-ow3bjypntyfbafke33olmxpdg46qgnpp/include/thallium/callable_remote_procedure.hpp:117][margo_provider_forward] Function returned HG_PERMISSION

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 678, in format
    record.message = record.getMessage()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/logging/__init__.py", line 368, in getMessage
    msg = msg % self.args
TypeError: not all arguments converted during string formatting
Call stack:
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/bin/dask", line 8, in <module>
    sys.exit(main())
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/dask/__main__.py", line 7, in main
    run_cli()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/dask/cli.py", line 209, in run_cli
    cli()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1078, in main
    rv = self.invoke(ctx)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py", line 251, in main
    asyncio_run(run(), loop_factory=get_loop_factory())
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/compatibility.py", line 236, in asyncio_run
    return loop.run_until_complete(main)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 636, in run_until_complete
    self.run_forever()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 603, in run_forever
    self._run_once()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/base_events.py", line 1909, in _run_once
    handle._run()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 970, in _handle_comm
    result = await result
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5715, in add_client
    self.remove_client(client=client, stimulus_id=f"remove-client-{time()}")
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5741, in remove_client
    self.client_releases_keys(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 5430, in client_releases_keys
    self.transitions(recommendations, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 7984, in transitions
    self._transitions(recommendations, client_msgs, worker_msgs, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 2065, in _transitions
    new_recs, new_cmsgs, new_wmsgs = self._transition(key, finish, stimulus_id)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/scheduler.py", line 2022, in _transition
    plugin.transition(
  File "/lus/eagle/projects/radix-io/agueroudji/XGBoost/D2024-04-19_17:15:01_R48_W8/MofkaSchedulerPlugin.py", line 231, in transition
    logging.exception("Exception while calling transition method when sending", str(transition_data))
Message: 'Exception while calling transition method when sending'
Arguments: ('{\'key\': "(\'getitem-57342c589e8a55cd05e8e60bd966f68a\', 121)", \'thread\': None, \'worker\': None, \'prefix\': \'getitem\', \'group\': \'getitem-57342c589e8a55cd05e8e60bd966f68a\', \'start\': \'released\', \'finish\': \'forgotten\', \'stimulus_id\': \'remove-client-1713550049.4507859\', \'called_from\': \'tcp://10.201.1.129:8786\', \'begins\': None, \'ends\': None, \'duration\': None, \'size\': None, \'time\': 1713550050.0157788}',)

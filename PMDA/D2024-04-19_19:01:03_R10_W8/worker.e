2024-04-19 19:01:35,813 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,813 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,814 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,814 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,814 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,814 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,814 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,815 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:36,045 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,045 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,046 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:38961'
2024-04-19 19:01:36,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:35043'
2024-04-19 19:01:36,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:44037'
2024-04-19 19:01:36,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:42369'
2024-04-19 19:01:36,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:33203'
2024-04-19 19:01:36,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:37197'
2024-04-19 19:01:36,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:34465'
2024-04-19 19:01:36,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.19:39057'
2024-04-19 19:01:37,112 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,112 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,113 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,113 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,131 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,132 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,132 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,132 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,132 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,132 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,132 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,132 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,132 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,133 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,133 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,133 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,158 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,158 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,176 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,177 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,177 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,177 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,178 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,178 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,143 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,144 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:39,470 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f0b79849-8ccb-475f-a497-65101b2bbfae
2024-04-19 19:01:39,470 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-075f1422-4939-4c8e-b3ca-8ac63c8be63d
2024-04-19 19:01:39,470 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:43619
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:43619
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:36321
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:36321
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:33509
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f745b1db-35e4-4f74-ba59-58ddb684748d
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:35707
2024-04-19 19:01:39,471 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-b85191ea-9667-46c3-96bc-da676a13bd90
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:41961
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:41961
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:39381
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,470 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f37a5753-876d-4dea-96a9-e616a2ad0454
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:40351
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:40351
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:39875
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,470 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-2ce32d18-6c8c-4cfe-b34d-aa4848da376b
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:46431
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:46431
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:41285
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1u8itm1c
2024-04-19 19:01:39,470 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-22a5352e-5fa1-4c88-9ee3-ba9e25fb26f5
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:42045
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:42045
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:33801
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8xu8ykf1
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-94206022-4c7b-434c-a53e-6f8ee3eea106
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.19:46271
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:46271
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:34967
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3v1atvf5
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:41007
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-12y8twd9
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_xqk0f7p
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.19:35707
2024-04-19 19:01:39,471 - distributed.worker - INFO -          dashboard at:          10.201.4.19:46325
2024-04-19 19:01:39,471 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.252:8786
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v2jbrqao
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ef7lkzil
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,471 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5h9yxfou
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,471 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,337 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,337 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,337 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,338 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,338 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,339 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,339 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,347 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,348 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,348 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,348 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,349 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,349 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,350 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,350 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,350 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,350 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,351 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,351 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,351 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,352 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,352 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,352 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,353 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,353 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,353 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:01:42,354 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.252:8786
2024-04-19 19:01:42,354 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,354 - distributed.core - INFO - Starting established connection to tcp://10.201.3.252:8786
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:42045. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:36321. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:35707. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:41961. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:40351. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:46431. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:46271. Reason: scheduler-close
2024-04-19 19:02:20,179 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.19:43619. Reason: scheduler-close
2024-04-19 19:02:20,181 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:37197'. Reason: scheduler-close
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40766 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40766 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40742 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40742 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40800 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40800 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40808 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40808 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,186 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:35043'. Reason: scheduler-close
2024-04-19 19:02:20,187 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:34465'. Reason: scheduler-close
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40786 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40786 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40764 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40764 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,187 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:44037'. Reason: scheduler-close
2024-04-19 19:02:20,187 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:39057'. Reason: scheduler-close
2024-04-19 19:02:20,180 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40770 remote=tcp://10.201.3.252:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.19:40770 remote=tcp://10.201.3.252:8786>: Stream is closed
2024-04-19 19:02:20,187 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:33203'. Reason: scheduler-close
2024-04-19 19:02:20,188 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:38961'. Reason: scheduler-close
2024-04-19 19:02:20,188 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.19:42369'. Reason: scheduler-close
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,303 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,304 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,304 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.252:8786; closing.
2024-04-19 19:02:20,304 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:22,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,305 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,305 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,305 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:42369'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,655 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,661 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:33203'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,661 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,679 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:35043'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,679 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,720 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:34465'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,720 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:39057'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,792 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,798 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:37197'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,798 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,804 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:44037'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,805 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:23,172 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.19:38961'. Reason: nanny-close-gracefully
2024-04-19 19:02:23,172 - distributed.dask_worker - INFO - End worker

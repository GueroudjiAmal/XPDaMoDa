2024-04-19 19:01:35,753 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,754 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,754 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,754 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,754 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,755 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,755 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,755 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:35,997 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:36,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:42973'
2024-04-19 19:01:36,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:44255'
2024-04-19 19:01:36,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:38461'
2024-04-19 19:01:36,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:35553'
2024-04-19 19:01:36,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:32935'
2024-04-19 19:01:36,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:36081'
2024-04-19 19:01:36,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:46647'
2024-04-19 19:01:36,085 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.17:39247'
2024-04-19 19:01:37,070 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,070 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,071 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,071 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,081 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,082 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,082 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,082 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,082 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,082 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,082 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,082 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-19 19:01:37,083 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,083 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,083 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,083 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-19 19:01:37,115 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,116 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,126 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,126 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,127 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,127 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,127 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:37,127 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-19 19:01:38,105 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,105 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,105 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,105 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,109 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,110 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,110 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:38,113 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-837a5d02-e027-41bb-aabf-6670236e0ef1
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-af33f68c-2fe8-4d01-b3ef-369fae1e46dc
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:45407
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f1ff13b9-4f5d-46aa-9318-bc2742f9daf8
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:36723
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:36723
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-bb730e53-01e1-47aa-865b-9ea4b2396390
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:37637
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:37637
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:40393
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:38345
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:38345
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:45319
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,428 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mfff_mqz
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:45407
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:40677
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,428 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wdo2hq8l
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-49ed863a-89ab-4e9c-844e-1b1538be1059
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:40773
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:40773
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:45697
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,428 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ephenmqm
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-843b07bd-9ffe-439b-9f9b-ec4f9c006b90
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:40865
2024-04-19 19:01:39,428 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:40865
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:44013
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,429 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,429 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2piltcb7
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -          dashboard at:          10.201.3.17:36859
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,428 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k9y6o4y6
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-d9615105-f758-4612-8e51-bf0c31a19ced
2024-04-19 19:01:39,428 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:35967
2024-04-19 19:01:39,429 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:35967
2024-04-19 19:01:39,429 - distributed.worker - INFO -          dashboard at:          10.201.3.17:36085
2024-04-19 19:01:39,429 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,429 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,429 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-eicjrgpw
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,428 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,429 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1dl6_kut
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,428 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-4da4c525-4875-4c4a-bbd7-219f294ba1a4
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.17:36903
2024-04-19 19:01:39,429 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.17:36903
2024-04-19 19:01:39,429 - distributed.worker - INFO -          dashboard at:          10.201.3.17:45335
2024-04-19 19:01:39,429 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.18:8786
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:39,429 - distributed.worker - INFO -               Threads:                          8
2024-04-19 19:01:39,429 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-19 19:01:39,429 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f3qnn_0d
2024-04-19 19:01:39,429 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,574 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,575 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,575 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,575 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,576 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,576 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,576 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,581 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,581 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,582 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,582 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,582 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,583 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,583 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,583 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,584 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,584 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,585 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,585 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,585 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,585 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,586 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,586 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,587 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-19 19:01:42,587 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:01:42,587 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.18:8786
2024-04-19 19:01:42,587 - distributed.worker - INFO - -------------------------------------------------
2024-04-19 19:01:42,588 - distributed.core - INFO - Starting established connection to tcp://10.201.3.18:8786
2024-04-19 19:02:20,324 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:45407. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:36723. Reason: scheduler-close
2024-04-19 19:02:20,324 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:35967. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:37637. Reason: scheduler-close
2024-04-19 19:02:20,324 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:36903. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:38345. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:40865. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.17:40773. Reason: scheduler-close
2024-04-19 19:02:20,326 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:39247'. Reason: scheduler-close
2024-04-19 19:02:20,325 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44208 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44208 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,325 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44214 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44214 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,325 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44236 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44236 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,326 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44212 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44212 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,326 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44244 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44244 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,325 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44228 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44228 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,325 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44200 remote=tcp://10.201.3.18:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.17:44200 remote=tcp://10.201.3.18:8786>: Stream is closed
2024-04-19 19:02:20,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:46647'. Reason: scheduler-close
2024-04-19 19:02:20,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:42973'. Reason: scheduler-close
2024-04-19 19:02:20,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:44255'. Reason: scheduler-close
2024-04-19 19:02:20,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:38461'. Reason: scheduler-close
2024-04-19 19:02:20,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:32935'. Reason: scheduler-close
2024-04-19 19:02:20,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:36081'. Reason: scheduler-close
2024-04-19 19:02:20,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.17:35553'. Reason: scheduler-close
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:20,450 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.18:8786; closing.
2024-04-19 19:02:20,450 - distributed.nanny - INFO - Worker closed
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-19 19:02:22,793 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:39247'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,794 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,801 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:36081'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,802 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,817 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:42973'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,818 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,823 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:46647'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,824 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,830 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:35553'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,831 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,836 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:32935'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,837 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:22,926 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:38461'. Reason: nanny-close-gracefully
2024-04-19 19:02:22,927 - distributed.dask_worker - INFO - End worker
2024-04-19 19:02:23,358 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.17:44255'. Reason: nanny-close-gracefully
2024-04-19 19:02:23,359 - distributed.dask_worker - INFO - End worker

2024-04-18 19:26:28,414 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:28,414 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:28,415 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:28,415 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:28,447 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:28,447 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:28,447 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:28,447 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:28,493 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.24:40221'
2024-04-18 19:26:28,493 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.24:34499'
2024-04-18 19:26:28,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.24:46877'
2024-04-18 19:26:28,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.24:44857'
2024-04-18 19:26:29,157 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:29,157 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:29,157 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:29,157 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:29,158 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,158 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,158 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,158 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,180 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,180 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,180 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,180 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,722 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,722 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,723 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,723 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:29,835 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,835 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,836 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,835 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:29,853 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.26:35611'
2024-04-18 19:26:29,853 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.26:44977'
2024-04-18 19:26:29,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.26:38775'
2024-04-18 19:26:29,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.4.26:34907'
2024-04-18 19:26:29,991 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:29,991 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:29,991 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:29,991 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:30,815 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:30,815 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:30,815 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:30,815 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:30,815 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:30,816 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:30,816 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:30,816 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:30,860 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:30,861 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:30,861 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:30,861 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:30,950 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-1aff1a32-ddd3-4bc9-9480-ae5840863f98
2024-04-18 19:26:30,951 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.24:38611
2024-04-18 19:26:30,951 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-9845f359-9f12-4cfe-a634-ac13e10b2f45
2024-04-18 19:26:30,951 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.24:38611
2024-04-18 19:26:30,951 - distributed.worker - INFO -          dashboard at:          10.201.4.24:46127
2024-04-18 19:26:30,951 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:30,951 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.24:43255
2024-04-18 19:26:30,951 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,951 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:30,951 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:30,951 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.24:43255
2024-04-18 19:26:30,951 - distributed.worker - INFO -          dashboard at:          10.201.4.24:45799
2024-04-18 19:26:30,951 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1inckkr0
2024-04-18 19:26:30,951 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,951 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:30,951 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,951 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:30,951 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:30,951 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z4htkvgg
2024-04-18 19:26:30,951 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,953 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-b7ba46ef-bcab-4b1d-a46a-7b8f5ebb3671
2024-04-18 19:26:30,954 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.24:45103
2024-04-18 19:26:30,954 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.24:45103
2024-04-18 19:26:30,954 - distributed.worker - INFO -          dashboard at:          10.201.4.24:33653
2024-04-18 19:26:30,954 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:30,954 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,954 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:30,954 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:30,954 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aktq2vxh
2024-04-18 19:26:30,954 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,956 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-2d22bcaa-a56e-4fc5-b080-66d0d21d7753
2024-04-18 19:26:30,956 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.24:36251
2024-04-18 19:26:30,956 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.24:36251
2024-04-18 19:26:30,956 - distributed.worker - INFO -          dashboard at:          10.201.4.24:34217
2024-04-18 19:26:30,956 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:30,956 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:30,956 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:30,956 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:30,957 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4kw37xny
2024-04-18 19:26:30,957 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:31,804 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:31,804 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:31,804 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:31,804 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:32,806 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-bdc4e60a-3b67-4d06-8b8f-5c3e701db8fc
2024-04-18 19:26:32,806 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.26:32913
2024-04-18 19:26:32,806 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-4316bffd-53b6-454d-8129-ff5e7306fc7b
2024-04-18 19:26:32,806 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-fa5c56c5-bb25-49c9-8b67-664e1da81988
2024-04-18 19:26:32,806 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.26:32913
2024-04-18 19:26:32,806 - distributed.worker - INFO -          dashboard at:          10.201.4.26:43927
2024-04-18 19:26:32,806 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.26:39459
2024-04-18 19:26:32,806 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.26:39459
2024-04-18 19:26:32,806 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.26:44297
2024-04-18 19:26:32,806 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.26:44297
2024-04-18 19:26:32,806 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-eb4fa886-cd86-426b-add7-74cf418dd6e7
2024-04-18 19:26:32,806 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:32,806 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,806 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:32,806 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:32,806 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-01hzgoxu
2024-04-18 19:26:32,806 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,806 - distributed.worker - INFO -          dashboard at:          10.201.4.26:38667
2024-04-18 19:26:32,806 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:32,806 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,806 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:32,806 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:32,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ubzhz9wa
2024-04-18 19:26:32,807 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,806 - distributed.worker - INFO -          dashboard at:          10.201.4.26:40923
2024-04-18 19:26:32,806 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:32,806 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,807 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:32,807 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:32,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ufdyupyb
2024-04-18 19:26:32,807 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,806 - distributed.worker - INFO -       Start worker at:    tcp://10.201.4.26:34093
2024-04-18 19:26:32,807 - distributed.worker - INFO -          Listening to:    tcp://10.201.4.26:34093
2024-04-18 19:26:32,807 - distributed.worker - INFO -          dashboard at:          10.201.4.26:36275
2024-04-18 19:26:32,807 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.1.216:8786
2024-04-18 19:26:32,807 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:32,807 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:32,807 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:32,807 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vpgkgbqi
2024-04-18 19:26:32,807 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:33,291 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:33,291 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:33,292 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:33,292 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:33,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:33,293 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:33,293 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:33,294 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:33,296 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:33,296 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:33,296 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:33,297 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:33,298 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:33,298 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:33,298 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:33,299 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:35,240 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:35,241 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:35,241 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:35,242 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:35,242 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:35,242 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:35,242 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:35,243 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:35,243 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:35,243 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:35,244 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:35,244 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:26:35,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:35,244 - distributed.worker - INFO -         Registered to:    tcp://10.201.1.216:8786
2024-04-18 19:26:35,245 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:35,245 - distributed.core - INFO - Starting established connection to tcp://10.201.1.216:8786
2024-04-18 19:27:17,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:21,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:21,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:21,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:23,464 - distributed.utils_perf - INFO - full garbage collection released 30.53 MiB from 33 reference cycles (threshold: 9.54 MiB)
2024-04-18 19:27:24,139 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:24,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:24,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:24,144 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:27,514 - distributed.utils_perf - INFO - full garbage collection released 16.09 MiB from 0 reference cycles (threshold: 9.54 MiB)
2024-04-18 19:30:09,048 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,049 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.24:36251. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,051 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.24:43255. Reason: scheduler-close
2024-04-18 19:30:09,052 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,052 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.26:34093. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,053 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,053 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.24:45103. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,053 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.26:39459. Reason: scheduler-close
2024-04-18 19:30:09,053 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33028 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33028 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,050 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33048 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33048 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,054 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33036 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33036 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,055 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,055 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.26:44297. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,056 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.24:44857'. Reason: scheduler-close
2024-04-18 19:30:09,056 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.24:34499'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,056 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.24:46877'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,058 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,058 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.24:38611. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,057 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59568 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59568 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,056 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59580 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59580 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,053 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59596 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59596 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,060 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.26:35611'. Reason: scheduler-close
2024-04-18 19:30:09,061 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.26:34907'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,060 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33024 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.24:33024 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,061 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.26:38775'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,062 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.24:40221'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,064 - distributed.core - INFO - Connection to tcp://10.201.1.216:8786 has been closed.
2024-04-18 19:30:09,064 - distributed.worker - INFO - Stopping worker at tcp://10.201.4.26:32913. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59560 remote=tcp://10.201.1.216:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.4.26:59560 remote=tcp://10.201.1.216:8786>: Stream is closed
2024-04-18 19:30:09,068 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.4.26:44977'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:09,160 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,160 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,157 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:09,165 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,165 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,163 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:09,172 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.1.216:8786; closing.
2024-04-18 19:30:09,172 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,173 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,176 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.1.216:8786; closing.
2024-04-18 19:30:09,177 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:09,184 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:11,161 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,161 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,166 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,166 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,173 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,174 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,178 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:11,185 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:12,287 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.26:44977'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,288 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.24:34499'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,320 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,392 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.26:38775'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,393 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.26:34907'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,400 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,423 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.24:40221'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,424 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,429 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.24:46877'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,429 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,731 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.26:35611'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,732 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:12,771 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.4.24:44857'. Reason: nanny-close-gracefully
2024-04-18 19:30:12,771 - distributed.dask_worker - INFO - End worker

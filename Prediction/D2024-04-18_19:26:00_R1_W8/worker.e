2024-04-18 19:26:19,787 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:19,787 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:19,787 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:19,788 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:19,852 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:19,852 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:19,853 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:19,853 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:19,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.228:45405'
2024-04-18 19:26:19,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.228:34653'
2024-04-18 19:26:19,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.228:44581'
2024-04-18 19:26:19,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.228:40011'
2024-04-18 19:26:20,633 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:20,633 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:20,633 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:20,633 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:20,633 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:20,634 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:20,634 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:20,634 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:20,675 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:20,676 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:20,677 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:20,677 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:21,284 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:21,284 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:21,284 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:21,285 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:21,570 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:21,570 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:21,571 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:21,571 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:21,810 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:21,810 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:21,810 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:21,810 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:21,829 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.244:35707'
2024-04-18 19:26:21,829 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.244:44483'
2024-04-18 19:26:21,829 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.244:39793'
2024-04-18 19:26:21,830 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.244:41377'
2024-04-18 19:26:22,261 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-115e3eb6-f637-4e04-8aa4-ce1391f8396e
2024-04-18 19:26:22,261 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.228:35275
2024-04-18 19:26:22,261 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-0a3cddbf-a0bf-4a39-ac82-7ee313538c8c
2024-04-18 19:26:22,261 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.228:35275
2024-04-18 19:26:22,261 - distributed.worker - INFO -          dashboard at:         10.201.3.228:43371
2024-04-18 19:26:22,261 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:22,261 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,261 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:22,261 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:22,261 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rb1zlis0
2024-04-18 19:26:22,261 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.228:35987
2024-04-18 19:26:22,261 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.228:35987
2024-04-18 19:26:22,261 - distributed.worker - INFO -          dashboard at:         10.201.3.228:44477
2024-04-18 19:26:22,261 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:22,261 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,262 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:22,261 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,262 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:22,262 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fg2w_4yf
2024-04-18 19:26:22,262 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,262 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-95a0cffc-99b1-4883-91d0-50f8b56426ec
2024-04-18 19:26:22,263 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.228:42711
2024-04-18 19:26:22,263 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.228:42711
2024-04-18 19:26:22,263 - distributed.worker - INFO -          dashboard at:         10.201.3.228:33721
2024-04-18 19:26:22,263 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:22,263 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,263 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:22,263 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:22,263 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o6m7u6cp
2024-04-18 19:26:22,263 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,266 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-26bff00b-15ec-4ffe-9a59-f3b22b435260
2024-04-18 19:26:22,266 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.228:37899
2024-04-18 19:26:22,266 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.228:37899
2024-04-18 19:26:22,266 - distributed.worker - INFO -          dashboard at:         10.201.3.228:39333
2024-04-18 19:26:22,266 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:22,266 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,266 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:22,266 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:22,266 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vwqxzx6n
2024-04-18 19:26:22,266 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:22,823 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:22,823 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:22,823 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:22,823 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:22,824 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:22,824 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:22,824 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:22,824 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:22,868 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:22,868 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:22,868 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:22,869 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:23,383 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:23,384 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:23,384 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:23,384 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:23,385 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:23,386 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:23,386 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:23,386 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:23,386 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:23,387 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:23,387 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:23,387 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:23,388 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:23,388 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:23,388 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:23,389 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:23,827 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:23,827 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:23,827 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:23,827 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:24,884 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-8e12e902-96f3-4da5-a1d1-ae1f7a89678e
2024-04-18 19:26:24,885 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-4ee740b2-4af2-405b-9d1a-ef1d120a7fa5
2024-04-18 19:26:24,884 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.244:43033
2024-04-18 19:26:24,884 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.244:43033
2024-04-18 19:26:24,885 - distributed.worker - INFO -          dashboard at:         10.201.3.244:42087
2024-04-18 19:26:24,885 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:24,884 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-3524f9fc-a7e7-4f40-9533-432af9f192fa
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.244:33309
2024-04-18 19:26:24,885 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.244:33309
2024-04-18 19:26:24,885 - distributed.worker - INFO -          dashboard at:         10.201.3.244:44551
2024-04-18 19:26:24,885 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:24,884 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-90d3f46c-31a2-411f-ab3c-9f480e3f589d
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.244:37533
2024-04-18 19:26:24,885 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.244:37533
2024-04-18 19:26:24,885 - distributed.worker - INFO -          dashboard at:         10.201.3.244:39959
2024-04-18 19:26:24,885 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:24,885 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Start worker at:   tcp://10.201.3.244:38483
2024-04-18 19:26:24,885 - distributed.worker - INFO -          Listening to:   tcp://10.201.3.244:38483
2024-04-18 19:26:24,885 - distributed.worker - INFO -          dashboard at:         10.201.3.244:32793
2024-04-18 19:26:24,885 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.3.231:8786
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:24,885 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-27qe9565
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:24,885 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-23mitvzm
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pkcf8dur
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:24,885 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kzy9mvmg
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:24,885 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:29,479 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:29,479 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:29,480 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:29,480 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:29,480 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:29,481 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:29,481 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:29,482 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:29,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:29,487 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:29,487 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:29,488 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:29,494 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:29,494 - distributed.worker - INFO -         Registered to:    tcp://10.201.3.231:8786
2024-04-18 19:26:29,495 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:29,495 - distributed.core - INFO - Starting established connection to tcp://10.201.3.231:8786
2024-04-18 19:26:50,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:50,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:50,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:57,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:57,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:57,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:26:57,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:29:35,601 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.244:43033. Reason: scheduler-close
2024-04-18 19:29:35,602 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.244:37533. Reason: scheduler-close
2024-04-18 19:29:35,604 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.244:38483. Reason: scheduler-close
2024-04-18 19:29:35,605 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.244:33309. Reason: scheduler-close
2024-04-18 19:29:35,605 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.228:35987. Reason: scheduler-close
2024-04-18 19:29:35,607 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.228:37899. Reason: scheduler-close
2024-04-18 19:29:35,603 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42770 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42770 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,604 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42782 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42782 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,606 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42792 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42792 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.244:39793'. Reason: scheduler-close
2024-04-18 19:29:35,607 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42808 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.244:42808 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.244:44483'. Reason: scheduler-close
2024-04-18 19:29:35,609 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.244:35707'. Reason: scheduler-close
2024-04-18 19:29:35,607 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42218 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42218 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,609 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.244:41377'. Reason: scheduler-close
2024-04-18 19:29:35,610 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.228:42711. Reason: scheduler-close
2024-04-18 19:29:35,610 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.228:44581'. Reason: scheduler-close
2024-04-18 19:29:35,609 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42248 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42248 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,612 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.228:45405'. Reason: scheduler-close
2024-04-18 19:29:35,612 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42234 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42234 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,614 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.228:34653'. Reason: scheduler-close
2024-04-18 19:29:35,614 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.228:35275. Reason: scheduler-close
2024-04-18 19:29:35,617 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42208 remote=tcp://10.201.3.231:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.228:42208 remote=tcp://10.201.3.231:8786>: Stream is closed
2024-04-18 19:29:35,619 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.228:40011'. Reason: scheduler-close
2024-04-18 19:29:35,712 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,712 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,712 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,712 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,712 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,712 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,713 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,713 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,714 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,714 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,716 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,716 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,718 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,718 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:35,723 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.231:8786; closing.
2024-04-18 19:29:35,723 - distributed.nanny - INFO - Worker closed
2024-04-18 19:29:37,713 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,714 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,715 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,715 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,717 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,719 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,723 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:37,725 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:29:38,363 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.228:44581'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,363 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,369 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.228:45405'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,370 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,377 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.228:34653'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,378 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,822 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.244:44483'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,822 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,827 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.228:40011'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,827 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,927 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.244:41377'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,927 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:38,933 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.244:35707'. Reason: nanny-close-gracefully
2024-04-18 19:29:38,934 - distributed.dask_worker - INFO - End worker
2024-04-18 19:29:39,272 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.244:39793'. Reason: nanny-close-gracefully
2024-04-18 19:29:39,273 - distributed.dask_worker - INFO - End worker

2024-04-18 19:26:33,597 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:33,597 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:33,597 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:33,597 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:33,785 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:33,785 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:33,785 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:33,785 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:33,833 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.79:41351'
2024-04-18 19:26:33,834 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.79:36001'
2024-04-18 19:26:33,834 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.79:35727'
2024-04-18 19:26:33,834 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.79:45495'
2024-04-18 19:26:34,058 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,059 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,059 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,059 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,290 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,290 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,290 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,291 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.85:42739'
2024-04-18 19:26:34,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.85:34173'
2024-04-18 19:26:34,310 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.85:40681'
2024-04-18 19:26:34,310 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.3.85:35157'
2024-04-18 19:26:34,549 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:34,549 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:34,550 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:34,550 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:34,550 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,550 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,550 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,550 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,574 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,574 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,574 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,574 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,297 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,297 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,297 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,298 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,298 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,298 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,298 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,298 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,343 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,343 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,344 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,344 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,401 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:35,401 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:35,401 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:35,402 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,325 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,325 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,325 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,325 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,499 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-cd9ca420-7689-44bf-afa3-1fe240e733d8
2024-04-18 19:26:36,499 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-da7ad7f9-4ab7-4bbe-a9fa-bfdaa290140f
2024-04-18 19:26:36,499 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.79:44719
2024-04-18 19:26:36,500 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.79:44719
2024-04-18 19:26:36,500 - distributed.worker - INFO -          dashboard at:          10.201.3.79:42365
2024-04-18 19:26:36,500 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:36,500 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.79:36525
2024-04-18 19:26:36,500 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.79:36525
2024-04-18 19:26:36,500 - distributed.worker - INFO -          dashboard at:          10.201.3.79:36747
2024-04-18 19:26:36,500 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-268a6653-cbfb-4238-bc2f-bbbccb0b6d3b
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.79:37017
2024-04-18 19:26:36,500 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.79:37017
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ps_e_vif
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-e2fb73f4-484f-4e1c-963e-3f5f625955b5
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.79:38653
2024-04-18 19:26:36,500 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.79:38653
2024-04-18 19:26:36,500 - distributed.worker - INFO -          dashboard at:          10.201.3.79:43813
2024-04-18 19:26:36,500 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:36,500 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s1xn6ps5
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:36,500 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:36,500 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8pgf5xhq
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO -          dashboard at:          10.201.3.79:46545
2024-04-18 19:26:36,500 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:36,500 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:36,500 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:36,500 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:36,501 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0eywiey6
2024-04-18 19:26:36,501 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,248 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-e5bf88a8-89fd-4df6-99d0-93e5e3acce60
2024-04-18 19:26:37,248 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.85:43145
2024-04-18 19:26:37,248 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-6c3cc2df-f821-4e2e-b553-65579284a649
2024-04-18 19:26:37,248 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.85:43979
2024-04-18 19:26:37,248 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f7f93b8b-de54-4c5d-867c-006ddb55a887
2024-04-18 19:26:37,248 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.85:41317
2024-04-18 19:26:37,248 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.85:41317
2024-04-18 19:26:37,248 - distributed.worker - INFO -          dashboard at:          10.201.3.85:41917
2024-04-18 19:26:37,248 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:37,248 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.85:43145
2024-04-18 19:26:37,248 - distributed.worker - INFO -          dashboard at:          10.201.3.85:46517
2024-04-18 19:26:37,248 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,249 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,249 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wieu_0hy
2024-04-18 19:26:37,248 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-a888f211-6ea5-40ae-b1e6-673bdcf36448
2024-04-18 19:26:37,248 - distributed.worker - INFO -       Start worker at:    tcp://10.201.3.85:43987
2024-04-18 19:26:37,249 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.85:43987
2024-04-18 19:26:37,249 - distributed.worker - INFO -          dashboard at:          10.201.3.85:44545
2024-04-18 19:26:37,248 - distributed.worker - INFO -          Listening to:    tcp://10.201.3.85:43979
2024-04-18 19:26:37,249 - distributed.worker - INFO -          dashboard at:          10.201.3.85:40661
2024-04-18 19:26:37,249 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,249 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,249 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,249 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ocyckm0s
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO - Waiting to connect to:     tcp://10.201.3.80:8786
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,249 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,249 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qb1knop_
2024-04-18 19:26:37,249 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kf4h75ea
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,249 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,069 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,069 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,069 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,070 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,071 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,071 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,072 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,074 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,074 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,075 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,075 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,076 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,076 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,076 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,077 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,077 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,077 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,078 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,079 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,079 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,079 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,079 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,079 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,080 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:40,080 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:26:40,080 - distributed.worker - INFO -         Registered to:     tcp://10.201.3.80:8786
2024-04-18 19:26:40,081 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:40,081 - distributed.core - INFO - Starting established connection to tcp://10.201.3.80:8786
2024-04-18 19:27:20,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:25,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:25,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:25,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:30:13,169 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.79:44719. Reason: scheduler-close
2024-04-18 19:30:13,172 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.79:38653. Reason: scheduler-close
2024-04-18 19:30:13,173 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.85:41317. Reason: scheduler-close
2024-04-18 19:30:13,174 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.79:36525. Reason: scheduler-close
2024-04-18 19:30:13,174 - distributed.core - INFO - Connection to tcp://10.201.3.80:8786 has been closed.
2024-04-18 19:30:13,174 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.79:37017. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,175 - distributed.core - INFO - Connection to tcp://10.201.3.80:8786 has been closed.
2024-04-18 19:30:13,175 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.85:43979. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,174 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44904 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44904 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,170 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44892 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44892 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,176 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44914 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44914 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,176 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44912 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.79:44912 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,177 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.79:41351'. Reason: scheduler-close
2024-04-18 19:30:13,177 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.85:43987. Reason: scheduler-close
2024-04-18 19:30:13,177 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.79:36001'. Reason: scheduler-close
2024-04-18 19:30:13,178 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.79:45495'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,178 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.79:35727'. Reason: scheduler-close
2024-04-18 19:30:13,180 - distributed.core - INFO - Connection to tcp://10.201.3.80:8786 has been closed.
2024-04-18 19:30:13,180 - distributed.worker - INFO - Stopping worker at tcp://10.201.3.85:43145. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,176 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49790 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49790 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,175 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49778 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49778 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,179 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49800 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49800 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,182 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.85:42739'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,182 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.85:34173'. Reason: scheduler-close
2024-04-18 19:30:13,182 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.85:40681'. Reason: scheduler-close
2024-04-18 19:30:13,182 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49766 remote=tcp://10.201.3.80:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.3.85:49766 remote=tcp://10.201.3.80:8786>: Stream is closed
2024-04-18 19:30:13,184 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.3.85:35157'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:13,281 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,285 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,280 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distri2024-04-18 19:30:13,280 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
buted/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:13,280 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:13,284 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:13,284 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:13,297 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.80:8786; closing.
2024-04-18 19:30:13,297 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,301 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.80:8786; closing.
2024-04-18 19:30:13,301 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.80:8786; closing.
2024-04-18 19:30:13,303 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,303 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.80:8786; closing.
2024-04-18 19:30:13,303 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,304 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.3.80:8786; closing.
2024-04-18 19:30:13,305 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:13,306 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,282 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,286 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,298 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,302 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:15,306 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:16,369 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.79:35727'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,370 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.85:34173'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,381 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.79:41351'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,475 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,480 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.79:45495'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,481 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.85:35157'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,487 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,492 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.85:42739'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,493 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,803 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.79:36001'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,804 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:16,819 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.3.85:40681'. Reason: nanny-close-gracefully
2024-04-18 19:30:16,820 - distributed.dask_worker - INFO - End worker

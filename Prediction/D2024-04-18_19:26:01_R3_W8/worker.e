2024-04-18 19:26:34,262 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,262 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,262 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,262 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,400 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,400 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,400 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,400 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:34,507 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,507 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,507 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,507 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,545 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.212:36353'
2024-04-18 19:26:34,545 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.212:46463'
2024-04-18 19:26:34,546 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.212:36451'
2024-04-18 19:26:34,546 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.212:40583'
2024-04-18 19:26:34,632 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,632 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,632 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,633 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:34,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.210:45593'
2024-04-18 19:26:34,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.210:45847'
2024-04-18 19:26:34,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.210:36479'
2024-04-18 19:26:34,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.201.0.210:41383'
2024-04-18 19:26:35,513 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,513 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,513 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,513 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,514 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,514 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,514 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,514 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,558 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,559 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,559 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,559 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,614 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,615 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,615 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,615 - distributed.preloading - INFO - Creating preload: MofkaWorkerPlugin.py
2024-04-18 19:26:35,616 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,616 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,616 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,616 - distributed.utils - INFO - Reload module MofkaWorkerPlugin from .py file
2024-04-18 19:26:35,661 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,661 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,661 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:35,661 - distributed.preloading - INFO - Import preload module: MofkaWorkerPlugin.py
2024-04-18 19:26:36,537 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,537 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,537 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,537 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,660 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,661 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,661 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:36,661 - distributed.preloading - INFO - Run preload setup: MofkaWorkerPlugin.py
2024-04-18 19:26:37,588 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-3234ddb5-d69d-4630-80b5-343c4a511d66
2024-04-18 19:26:37,588 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-2d174b36-0b5e-4837-a999-1bb3b099ac67
2024-04-18 19:26:37,588 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-c64686da-0673-46ab-bde8-ddd3c84fe0bf
2024-04-18 19:26:37,588 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.212:46283
2024-04-18 19:26:37,588 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.212:40899
2024-04-18 19:26:37,588 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.212:40899
2024-04-18 19:26:37,588 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.212:40295
2024-04-18 19:26:37,588 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.212:40295
2024-04-18 19:26:37,588 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.212:46283
2024-04-18 19:26:37,588 - distributed.worker - INFO -          dashboard at:         10.201.0.212:46181
2024-04-18 19:26:37,588 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,589 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,588 - distributed.worker - INFO -          dashboard at:         10.201.0.212:43221
2024-04-18 19:26:37,589 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,588 - distributed.worker - INFO -          dashboard at:         10.201.0.212:42109
2024-04-18 19:26:37,589 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,589 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,589 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xnwog9jx
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,589 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-697xa1m3
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,588 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-89848bc6-b33a-4e9c-806c-be2a341af3d9
2024-04-18 19:26:37,589 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.212:39731
2024-04-18 19:26:37,589 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.212:39731
2024-04-18 19:26:37,589 - distributed.worker - INFO -          dashboard at:         10.201.0.212:39073
2024-04-18 19:26:37,589 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,589 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,589 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pah378or
2024-04-18 19:26:37,589 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,589 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,589 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p3dfstjf
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,589 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,748 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-f5ae6ed5-0ca4-4a6a-b116-b6dd0947da4f
2024-04-18 19:26:37,748 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-05c807cd-244b-48d3-b65e-aa5e7b504f49
2024-04-18 19:26:37,748 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.210:46055
2024-04-18 19:26:37,749 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.210:46055
2024-04-18 19:26:37,749 - distributed.worker - INFO -          dashboard at:         10.201.0.210:46563
2024-04-18 19:26:37,749 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,748 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-5264ee8c-b8d8-4723-b0f6-ec5108bc364b
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.210:41207
2024-04-18 19:26:37,749 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.210:41207
2024-04-18 19:26:37,749 - distributed.worker - INFO -          dashboard at:         10.201.0.210:41329
2024-04-18 19:26:37,749 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,749 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,749 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jvohmdz6
2024-04-18 19:26:37,748 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.210:45981
2024-04-18 19:26:37,749 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.210:45981
2024-04-18 19:26:37,749 - distributed.worker - INFO -          dashboard at:         10.201.0.210:38819
2024-04-18 19:26:37,749 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,749 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,749 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f2z_znts
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,748 - distributed.worker - INFO - Starting Worker plugin MofkaWorkerPlugin-aae2c718-37ad-4923-9d5c-6cfc4be3e5f5
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Start worker at:   tcp://10.201.0.210:36053
2024-04-18 19:26:37,749 - distributed.worker - INFO -          Listening to:   tcp://10.201.0.210:36053
2024-04-18 19:26:37,749 - distributed.worker - INFO -          dashboard at:         10.201.0.210:43971
2024-04-18 19:26:37,749 - distributed.worker - INFO - Waiting to connect to:    tcp://10.201.0.222:8786
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,749 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,749 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a17yqh05
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,749 - distributed.worker - INFO -               Threads:                          8
2024-04-18 19:26:37,749 - distributed.worker - INFO -                Memory:                 503.22 GiB
2024-04-18 19:26:37,749 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d4y7_wd_
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:37,749 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,349 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,350 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,350 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,352 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,352 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,352 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,355 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,355 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,355 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,355 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,356 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,356 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,357 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,357 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,357 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,357 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,358 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,359 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,359 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,359 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,359 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,359 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,360 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:26:41,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-18 19:26:41,361 - distributed.worker - INFO -         Registered to:    tcp://10.201.0.222:8786
2024-04-18 19:26:41,361 - distributed.worker - INFO - -------------------------------------------------
2024-04-18 19:26:41,361 - distributed.core - INFO - Starting established connection to tcp://10.201.0.222:8786
2024-04-18 19:27:21,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:28,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2024-04-18 19:27:31,851 - distributed.utils_perf - INFO - full garbage collection released 32.21 MiB from 179 reference cycles (threshold: 9.54 MiB)
2024-04-18 19:30:15,719 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.210:36053. Reason: scheduler-close
2024-04-18 19:30:15,721 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,721 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.210:41207. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,721 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.212:40295. Reason: scheduler-close
2024-04-18 19:30:15,723 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,723 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.212:39731. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,726 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,726 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.210:45981. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,727 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,723 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37484 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37484 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,721 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37476 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37476 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,727 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.210:46055. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,728 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.210:41383'. Reason: scheduler-close
2024-04-18 19:30:15,728 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.210:36479'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,725 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49788 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49788 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,723 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49754 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49754 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,728 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37460 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37460 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,728 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37446 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.210:37446 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,730 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.212:46463'. Reason: scheduler-close
2024-04-18 19:30:15,730 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.212:36353'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,731 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.210:45847'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,731 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.210:45593'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,733 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,734 - distributed.core - INFO - Connection to tcp://10.201.0.222:8786 has been closed.
2024-04-18 19:30:15,734 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.212:46283. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,734 - distributed.worker - INFO - Stopping worker at tcp://10.201.0.212:40899. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,735 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49770 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49770 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,735 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49786 remote=tcp://10.201.0.222:8786>
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.201.0.212:49786 remote=tcp://10.201.0.222:8786>: Stream is closed
2024-04-18 19:30:15,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.212:36451'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.201.0.212:40583'. Reason: worker-handle-scheduler-connection-broken
2024-04-18 19:30:15,832 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,834 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,835 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,830 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:15,835 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,833 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/._view/ycbghmgvq7z34ridg4nntzus2jsgkcos/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/home/agueroudji/spack/var/spack/environments/mofkadask/.spack-env/view/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-04-18 19:30:15,838 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.0.222:8786; closing.
2024-04-18 19:30:15,838 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,840 - distributed.core - INFO - Received 'close-stream' from tcp://10.201.0.222:8786; closing.
2024-04-18 19:30:15,840 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,843 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:15,843 - distributed.nanny - INFO - Worker closed
2024-04-18 19:30:17,834 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,835 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,836 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,836 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,839 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,842 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,844 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:17,844 - distributed.nanny - ERROR - Worker process died unexpectedly
2024-04-18 19:30:19,204 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.210:41383'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,205 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,211 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.212:36353'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,212 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,313 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.210:45847'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,314 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,317 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.212:40583'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,318 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.210:36479'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,320 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,323 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.212:36451'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,324 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,642 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.212:46463'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,643 - distributed.dask_worker - INFO - End worker
2024-04-18 19:30:19,645 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.201.0.210:45593'. Reason: nanny-close-gracefully
2024-04-18 19:30:19,646 - distributed.dask_worker - INFO - End worker
